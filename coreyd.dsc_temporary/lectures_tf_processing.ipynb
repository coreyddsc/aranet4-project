{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as datetime\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npz file\n",
    "loaded_data = np.load('../datasets/windows.npz', allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the column names\n",
    "column_names = loaded_data['column_names']\n",
    "\n",
    "# Convert the loaded data back to a dictionary of lists of DataFrames, using the column names\n",
    "windows_df = {label: [pd.DataFrame(array, columns=column_names) for array in arrays_list] \n",
    "              for label, arrays_list in loaded_data.items() if label != 'column_names'}\n",
    "\n",
    "# Loop through windows_df and set 'Datetime' as the index\n",
    "for label, windows_list in windows_df.items():\n",
    "    for i, window in enumerate(windows_list):\n",
    "        # Convert 'Datetime' to a datetime object\n",
    "        window['Datetime'] = pd.to_datetime(window['Datetime'])\n",
    "\n",
    "        # Set 'Datetime' as the index\n",
    "        windows_df[label][i] = window.set_index('Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Chen\n",
      "Window 0: (76, 9)\n",
      "Window 1: (76, 9)\n",
      "Window 2: (76, 9)\n",
      "Window 3: (76, 9)\n",
      "Window 4: (76, 9)\n",
      "Window 5: (76, 9)\n",
      "Window 6: (76, 9)\n",
      "Window 7: (76, 9)\n",
      "Window 8: (76, 9)\n",
      "Window 9: (76, 9)\n",
      "Window 10: (76, 9)\n",
      "Window 11: (76, 9)\n",
      "Label: Song\n",
      "Window 0: (76, 9)\n",
      "Window 1: (76, 9)\n",
      "Window 2: (76, 9)\n",
      "Window 3: (76, 9)\n",
      "Window 4: (76, 9)\n",
      "Window 5: (76, 9)\n",
      "Window 6: (76, 9)\n",
      "Window 7: (76, 9)\n",
      "Window 8: (76, 9)\n",
      "Window 9: (76, 9)\n",
      "Window 10: (76, 9)\n",
      "Window 11: (76, 9)\n",
      "Window 12: (76, 9)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of each DataFrame in the windows dictionary\n",
    "for label, windows_list in windows_df.items():\n",
    "    print(f\"Label: {label}\")\n",
    "    for i, window in enumerate(windows_list):\n",
    "        print(f\"Window {i}: {window.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 76 entries, 2024-03-14 12:15:00 to 2024-03-14 13:30:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   co2            76 non-null     object\n",
      " 1   tempF          76 non-null     object\n",
      " 2   rhumid         76 non-null     object\n",
      " 3   atmpr          76 non-null     object\n",
      " 4   door1          76 non-null     object\n",
      " 5   door2          76 non-null     object\n",
      " 6   hvac           76 non-null     object\n",
      " 7   subject_count  76 non-null     object\n",
      " 8   lecturer       76 non-null     object\n",
      "dtypes: object(9)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "windows_df['Song'][0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "      <th>tempF</th>\n",
       "      <th>rhumid</th>\n",
       "      <th>atmpr</th>\n",
       "      <th>door1</th>\n",
       "      <th>door2</th>\n",
       "      <th>hvac</th>\n",
       "      <th>subject_count</th>\n",
       "      <th>lecturer</th>\n",
       "      <th>co2_ma3</th>\n",
       "      <th>co2_ma5</th>\n",
       "      <th>co2_lag1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:15:00</th>\n",
       "      <td>773.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>773.000000</td>\n",
       "      <td>773.000000</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:16:00</th>\n",
       "      <td>770.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>771.500000</td>\n",
       "      <td>771.500000</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:17:00</th>\n",
       "      <td>786.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>776.333333</td>\n",
       "      <td>776.333333</td>\n",
       "      <td>770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:18:00</th>\n",
       "      <td>798.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>784.666667</td>\n",
       "      <td>781.750000</td>\n",
       "      <td>786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:19:00</th>\n",
       "      <td>824.0</td>\n",
       "      <td>74.1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>802.666667</td>\n",
       "      <td>790.200000</td>\n",
       "      <td>798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       co2 tempF rhumid   atmpr door1 door2 hvac  \\\n",
       "Datetime                                                           \n",
       "2024-03-14 12:15:00  773.0  74.5   37.0  1018.1     1     1    0   \n",
       "2024-03-14 12:16:00  770.0  74.4   37.0  1018.1     1     1    0   \n",
       "2024-03-14 12:17:00  786.0  74.4   36.0  1018.1     1     1    0   \n",
       "2024-03-14 12:18:00  798.0  74.2   36.0  1018.0     1     1    0   \n",
       "2024-03-14 12:19:00  824.0  74.1   36.0  1018.1     1     1    0   \n",
       "\n",
       "                    subject_count lecturer     co2_ma3     co2_ma5  co2_lag1  \n",
       "Datetime                                                                      \n",
       "2024-03-14 12:15:00           3.0        1  773.000000  773.000000     773.0  \n",
       "2024-03-14 12:16:00           3.0        1  771.500000  771.500000     773.0  \n",
       "2024-03-14 12:17:00           3.0        1  776.333333  776.333333     770.0  \n",
       "2024-03-14 12:18:00           3.0        1  784.666667  781.750000     786.0  \n",
       "2024-03-14 12:19:00           3.0        1  802.666667  790.200000     798.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess each DataFrame in windows_df\n",
    "for label, windows_list in windows_df.items():\n",
    "    for window in windows_list:\n",
    "        \n",
    "        # Ensure that the 'co2' column is numeric\n",
    "        window['co2'] = pd.to_numeric(window['co2'], errors='coerce')\n",
    "        \n",
    "        # Create rolling average for CO2 with a window of 3 (change this as needed)\n",
    "        window['co2_ma3'] = window['co2'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "        # Create rolling average for CO2 with a window of 3 (change this as needed)\n",
    "        window['co2_ma5'] = window['co2'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "        # Create rolling average for CO2 with a window of 3 (change this as needed)\n",
    "        # window['co2_std5'] = window['co2'].rolling(window=5, min_periods=1).std()\n",
    "        \n",
    "        # Create shift (lag) features for CO2\n",
    "        # window['co2_std5'] = window['co2_std5'].fillna(method='bfill')\n",
    "\n",
    "        # Create shift (lag) features for CO2\n",
    "        window['co2_lag1'] = window['co2'].shift(1).fillna(method='bfill')\n",
    "        \n",
    "        # Create difference feature for CO2\n",
    "        # window['co2_diff'] = window['co2'].diff().fillna(0)\n",
    "\n",
    "# Example: Display the first DataFrame for 'Song' label after preprocessing\n",
    "windows_df['Song'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Chen, Number of windows: 12\n",
      "Label: Song, Number of windows: 13\n"
     ]
    }
   ],
   "source": [
    "# Convert the loaded data back to a dictionary of lists of NumPy arrays, excluding 'column_names'\n",
    "windows = {label: list(arrays) for label, arrays in windows_df.items() if label != 'column_names'}\n",
    "\n",
    "\n",
    "for label, windows_list in windows.items():\n",
    "    print(f\"Label: {label}, Number of windows: {len(windows_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 76 entries, 2024-03-14 12:15:00 to 2024-03-14 13:30:00\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   co2            76 non-null     float64\n",
      " 1   tempF          76 non-null     object \n",
      " 2   rhumid         76 non-null     object \n",
      " 3   atmpr          76 non-null     object \n",
      " 4   door1          76 non-null     object \n",
      " 5   door2          76 non-null     object \n",
      " 6   hvac           76 non-null     object \n",
      " 7   subject_count  76 non-null     object \n",
      " 8   lecturer       76 non-null     object \n",
      " 9   co2_ma3        76 non-null     float64\n",
      " 10  co2_ma5        76 non-null     float64\n",
      " 11  co2_lag1       76 non-null     float64\n",
      "dtypes: float64(4), object(8)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "windows['Song'][0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stacked all DataFrames into a 3D NumPy array.\n",
      "Shape of the final array X: (25, 76, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to collect all the 2D arrays\n",
    "all_arrays = []\n",
    "\n",
    "# Loop through each label in windows_df\n",
    "for label, windows_list in windows_df.items():\n",
    "    for window in windows_list:\n",
    "        # Convert the DataFrame to a NumPy array and add it to the list\n",
    "        all_arrays.append(window.values)  # Using .values to convert DataFrame to NumPy array\n",
    "\n",
    "# Stack all 2D arrays into a 3D array (assuming they all have the same number of columns)\n",
    "# If the number of rows varies, this step will fail and you might need to handle variable shapes differently\n",
    "try:\n",
    "    X = np.stack(all_arrays, axis=0)\n",
    "    print(\"Successfully stacked all DataFrames into a 3D NumPy array.\")\n",
    "except ValueError as e:\n",
    "    print(\"Error stacking arrays. This might be due to differing shapes:\", str(e))\n",
    "    # If shapes differ, use a general Python list or an array of objects\n",
    "    X = np.array(all_arrays, dtype=object)\n",
    "    print(\"Stored arrays in an object dtype array.\")\n",
    "\n",
    "print(\"Shape of the final array X:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[595.0, 65.8, 40.0, 1017.0, 1, 1, 1, 10.0, 0, 595.0, 595.0, 595.0],\n",
       "       [597.0, 66.4, 39.0, 1016.9, 1, 1, 1, 10.0, 0, 596.0, 596.0, 595.0],\n",
       "       [584.0, 66.8, 39.0, 1016.9, 1, 1, 0, 16.0, 0, 592.0, 592.0, 597.0],\n",
       "       [611.0, 67.2, 39.0, 1017.0, 1, 1, 0, 16.0, 0, 597.3333333333334,\n",
       "        596.75, 584.0],\n",
       "       [577.0, 67.5, 39.0, 1017.0, 1, 1, 0, 16.0, 0, 590.6666666666666,\n",
       "        592.8, 611.0],\n",
       "       [587.0, 67.8, 39.0, 1016.9, 1, 1, 0, 16.0, 0, 591.6666666666666,\n",
       "        591.2, 577.0],\n",
       "       [596.0, 67.9, 38.0, 1017.0, 1, 1, 0, 16.0, 0, 586.6666666666666,\n",
       "        591.0, 587.0],\n",
       "       [577.0, 68.2, 38.0, 1017.0, 1, 1, 0, 16.0, 0, 586.6666666666666,\n",
       "        589.6, 596.0],\n",
       "       [586.0, 68.4, 38.0, 1017.0, 1, 1, 0, 18.0, 0, 586.3333333333334,\n",
       "        584.6, 577.0],\n",
       "       [588.0, 68.5, 38.0, 1017.1, 1, 1, 0, 18.0, 0, 583.6666666666666,\n",
       "        586.8, 586.0],\n",
       "       [587.0, 68.5, 38.0, 1017.1, 1, 1, 0, 18.0, 0, 587.0, 586.8, 588.0],\n",
       "       [599.0, 68.6, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 591.3333333333334,\n",
       "        587.4, 587.0],\n",
       "       [616.0, 68.7, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 600.6666666666666,\n",
       "        595.2, 599.0],\n",
       "       [596.0, 68.9, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 603.6666666666666,\n",
       "        597.2, 616.0],\n",
       "       [594.0, 68.9, 37.0, 1017.1, 1, 1, 0, 18.0, 0, 602.0, 598.4, 596.0],\n",
       "       [612.0, 69.0, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 600.6666666666666,\n",
       "        603.4, 594.0],\n",
       "       [619.0, 69.0, 37.0, 1017.3, 1, 1, 0, 18.0, 0, 608.3333333333334,\n",
       "        607.4, 612.0],\n",
       "       [615.0, 69.1, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 615.3333333333334,\n",
       "        607.2, 619.0],\n",
       "       [629.0, 69.1, 37.0, 1017.2, 1, 1, 1, 18.0, 0, 621.0, 613.8, 615.0],\n",
       "       [620.0, 69.3, 37.0, 1017.4, 1, 1, 1, 18.0, 0, 621.3333333333334,\n",
       "        619.0, 629.0],\n",
       "       [635.0, 69.3, 37.0, 1017.2, 1, 1, 1, 18.0, 0, 628.0, 623.6, 620.0],\n",
       "       [630.0, 69.3, 36.0, 1017.1, 1, 1, 1, 18.0, 0, 628.3333333333334,\n",
       "        625.8, 635.0],\n",
       "       [626.0, 69.4, 36.0, 1017.1, 1, 1, 1, 18.0, 0, 630.3333333333334,\n",
       "        628.0, 630.0],\n",
       "       [626.0, 69.5, 36.0, 1017.1, 1, 1, 1, 18.0, 0, 627.3333333333334,\n",
       "        627.4, 626.0],\n",
       "       [608.0, 69.5, 36.0, 1017.2, 1, 1, 1, 18.0, 0, 620.0, 625.0, 626.0],\n",
       "       [636.0, 69.6, 36.0, 1017.2, 1, 1, 1, 18.0, 0, 623.3333333333334,\n",
       "        625.2, 608.0],\n",
       "       [615.0, 69.7, 36.0, 1017.1, 1, 1, 1, 18.0, 0, 619.6666666666666,\n",
       "        622.2, 636.0],\n",
       "       [600.0, 69.8, 36.0, 1017.2, 1, 1, 1, 18.0, 0, 617.0, 617.0, 615.0],\n",
       "       [613.0, 69.8, 36.0, 1017.2, 1, 1, 1, 18.0, 0, 609.3333333333334,\n",
       "        614.4, 600.0],\n",
       "       [611.0, 70.0, 36.0, 1017.3, 1, 1, 0, 18.0, 0, 608.0, 615.0, 613.0],\n",
       "       [622.0, 70.0, 36.0, 1017.3, 1, 1, 0, 18.0, 0, 615.3333333333334,\n",
       "        612.2, 611.0],\n",
       "       [593.0, 70.0, 35.0, 1017.3, 1, 1, 0, 18.0, 0, 608.6666666666666,\n",
       "        607.8, 622.0],\n",
       "       [618.0, 70.0, 35.0, 1017.3, 1, 1, 0, 18.0, 0, 611.0, 611.4, 593.0],\n",
       "       [607.0, 70.0, 35.0, 1017.3, 1, 1, 0, 18.0, 0, 606.0, 610.2, 618.0],\n",
       "       [623.0, 70.0, 35.0, 1017.3, 1, 1, 0, 18.0, 0, 616.0, 612.6, 607.0],\n",
       "       [627.0, 70.1, 35.0, 1017.3, 1, 1, 0, 18.0, 0, 619.0, 613.6, 623.0],\n",
       "       [644.0, 70.0, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 631.3333333333334,\n",
       "        623.8, 627.0],\n",
       "       [627.0, 70.1, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 632.6666666666666,\n",
       "        625.6, 644.0],\n",
       "       [643.0, 70.0, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 638.0, 632.8, 627.0],\n",
       "       [647.0, 70.1, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 639.0, 637.6, 643.0],\n",
       "       [655.0, 70.1, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 648.3333333333334,\n",
       "        643.2, 647.0],\n",
       "       [636.0, 70.1, 35.0, 1017.5, 1, 1, 0, 18.0, 0, 646.0, 641.6, 655.0],\n",
       "       [634.0, 70.1, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 641.6666666666666,\n",
       "        643.0, 636.0],\n",
       "       [625.0, 70.0, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 631.6666666666666,\n",
       "        639.4, 634.0],\n",
       "       [640.0, 70.1, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 633.0, 638.0, 625.0],\n",
       "       [642.0, 70.1, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 635.6666666666666,\n",
       "        635.4, 640.0],\n",
       "       [644.0, 70.1, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 642.0, 637.0, 642.0],\n",
       "       [638.0, 70.2, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 641.3333333333334,\n",
       "        637.8, 644.0],\n",
       "       [623.0, 70.3, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 635.0, 637.4, 638.0],\n",
       "       [659.0, 70.3, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 640.0, 641.2, 623.0],\n",
       "       [667.0, 70.3, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 649.6666666666666,\n",
       "        646.2, 659.0],\n",
       "       [638.0, 70.3, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 654.6666666666666,\n",
       "        645.0, 667.0],\n",
       "       [639.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 648.0, 645.2, 638.0],\n",
       "       [628.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 635.0, 646.2, 639.0],\n",
       "       [643.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 636.6666666666666,\n",
       "        643.0, 628.0],\n",
       "       [649.0, 70.5, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 640.0, 639.4, 643.0],\n",
       "       [639.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 643.6666666666666,\n",
       "        639.6, 649.0],\n",
       "       [652.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 646.6666666666666,\n",
       "        642.2, 639.0],\n",
       "       [659.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 650.0, 648.4, 652.0],\n",
       "       [668.0, 70.4, 35.0, 1017.3, 1, 1, 0, 18.0, 0, 659.6666666666666,\n",
       "        653.4, 659.0],\n",
       "       [675.0, 70.4, 35.0, 1017.4, 1, 1, 0, 18.0, 0, 667.3333333333334,\n",
       "        658.6, 668.0],\n",
       "       [644.0, 70.4, 34.0, 1017.3, 1, 1, 0, 18.0, 0, 662.3333333333334,\n",
       "        659.6, 675.0],\n",
       "       [653.0, 70.4, 34.0, 1017.4, 1, 1, 0, 18.0, 0, 657.3333333333334,\n",
       "        659.8, 644.0],\n",
       "       [680.0, 70.4, 34.0, 1017.4, 1, 1, 0, 18.0, 0, 659.0, 664.0, 653.0],\n",
       "       [654.0, 70.4, 34.0, 1017.4, 1, 1, 1, 18.0, 0, 662.3333333333334,\n",
       "        661.2, 680.0],\n",
       "       [667.0, 70.4, 34.0, 1017.3, 1, 1, 1, 18.0, 0, 667.0, 659.6, 654.0],\n",
       "       [664.0, 70.6, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 661.6666666666666,\n",
       "        663.6, 667.0],\n",
       "       [655.0, 70.9, 35.0, 1017.4, 1, 1, 1, 18.0, 0, 662.0, 664.0, 664.0],\n",
       "       [665.0, 71.1, 36.0, 1017.4, 1, 1, 1, 18.0, 0, 661.3333333333334,\n",
       "        661.0, 655.0],\n",
       "       [631.0, 71.2, 36.0, 1017.3, 1, 1, 1, 18.0, 0, 650.3333333333334,\n",
       "        656.4, 665.0],\n",
       "       [577.0, 71.5, 36.0, 1017.3, 1, 1, 1, 18.0, 0, 624.3333333333334,\n",
       "        638.4, 631.0],\n",
       "       [543.0, 71.9, 37.0, 1017.5, 1, 1, 1, 18.0, 0, 583.6666666666666,\n",
       "        614.2, 577.0],\n",
       "       [545.0, 72.1, 36.0, 1017.5, 1, 1, 1, 18.0, 0, 555.0, 592.2, 543.0],\n",
       "       [540.0, 72.4, 37.0, 1017.5, 1, 1, 1, 18.0, 0, 542.6666666666666,\n",
       "        567.2, 545.0],\n",
       "       [515.0, 72.9, 37.0, 1017.5, 1, 1, 1, 18.0, 0, 533.3333333333334,\n",
       "        544.0, 540.0],\n",
       "       [518.0, 73.2, 37.0, 1017.5, 1, 1, 1, 18.0, 0, 524.3333333333334,\n",
       "        532.2, 515.0]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (25, 76, 12)\n",
      "Shape of y: (25,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the 3D arrays and labels\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for label, windows_list in windows.items():\n",
    "    for window in windows_list:\n",
    "        # Convert each DataFrame to a NumPy array and append to the list\n",
    "        X_list.append(window)\n",
    "        # Append the corresponding label to the label list\n",
    "        y_list.append(label)\n",
    "\n",
    "# Convert the list of 3D arrays to a single 3D array (tensor)\n",
    "X = np.array(X_list)\n",
    "\n",
    "# Convert the label list to a NumPy array\n",
    "y = np.array(y_list)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `y` is our classifer, in this case it classifies lectures in `X` as `0` for `Song` or `1` for `Chen`. So if we take $n$ slices from each lecture intervals in each lecture $X_i \\in X$ to subsets $S_j \\in S$ such that $U_{j=0}^{n} S_j = X_i$, we will have to ensure labels from `y` are assigned accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisors of 76: [1, 2, 4, 19, 38, 76]\n"
     ]
    }
   ],
   "source": [
    "def find_divisors(n):\n",
    "    divisors = [i for i in range(1, n + 1) if n % i == 0]\n",
    "    return divisors\n",
    "\n",
    "# Find divisors of 76\n",
    "divisors_of_76 = find_divisors(76)\n",
    "print(\"Divisors of 76:\", divisors_of_76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of T: (100, 19, 12)\n",
      "New shape of y: (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your original array with shape (25, 76, 10)\n",
    "T = X.copy()\n",
    "\n",
    "# Verify that the second dimension is divisible by 2\n",
    "if T.shape[1] % 4 != 0:\n",
    "    raise ValueError(\"The number of records in each layer must be divisible by 2\")\n",
    "\n",
    "# Reshape T directly to the new shape\n",
    "# We reshape to (total number of new layers, new number of records per layer, number of features)\n",
    "# Total number of new layers = original layers * 2 because we split each layer into 2\n",
    "# New number of records per layer = original number of records per layer / 2\n",
    "new_layers = T.shape[0] * 4\n",
    "new_records_per_layer = T.shape[1] // 4\n",
    "T = T.reshape(new_layers, new_records_per_layer, T.shape[2])\n",
    "\n",
    "# Duplicate each element in y to match the new layer count\n",
    "y = np.repeat(y, 4)\n",
    "\n",
    "print(\"New shape of T:\", T.shape)\n",
    "print(\"New shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[595.0, 65.8, 40.0, 1017.0, 1, 1, 1, 10.0, 0, 595.0, 595.0, 595.0],\n",
       "       [597.0, 66.4, 39.0, 1016.9, 1, 1, 1, 10.0, 0, 596.0, 596.0, 595.0],\n",
       "       [584.0, 66.8, 39.0, 1016.9, 1, 1, 0, 16.0, 0, 592.0, 592.0, 597.0],\n",
       "       [611.0, 67.2, 39.0, 1017.0, 1, 1, 0, 16.0, 0, 597.3333333333334,\n",
       "        596.75, 584.0],\n",
       "       [577.0, 67.5, 39.0, 1017.0, 1, 1, 0, 16.0, 0, 590.6666666666666,\n",
       "        592.8, 611.0],\n",
       "       [587.0, 67.8, 39.0, 1016.9, 1, 1, 0, 16.0, 0, 591.6666666666666,\n",
       "        591.2, 577.0],\n",
       "       [596.0, 67.9, 38.0, 1017.0, 1, 1, 0, 16.0, 0, 586.6666666666666,\n",
       "        591.0, 587.0],\n",
       "       [577.0, 68.2, 38.0, 1017.0, 1, 1, 0, 16.0, 0, 586.6666666666666,\n",
       "        589.6, 596.0],\n",
       "       [586.0, 68.4, 38.0, 1017.0, 1, 1, 0, 18.0, 0, 586.3333333333334,\n",
       "        584.6, 577.0],\n",
       "       [588.0, 68.5, 38.0, 1017.1, 1, 1, 0, 18.0, 0, 583.6666666666666,\n",
       "        586.8, 586.0],\n",
       "       [587.0, 68.5, 38.0, 1017.1, 1, 1, 0, 18.0, 0, 587.0, 586.8, 588.0],\n",
       "       [599.0, 68.6, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 591.3333333333334,\n",
       "        587.4, 587.0],\n",
       "       [616.0, 68.7, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 600.6666666666666,\n",
       "        595.2, 599.0],\n",
       "       [596.0, 68.9, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 603.6666666666666,\n",
       "        597.2, 616.0],\n",
       "       [594.0, 68.9, 37.0, 1017.1, 1, 1, 0, 18.0, 0, 602.0, 598.4, 596.0],\n",
       "       [612.0, 69.0, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 600.6666666666666,\n",
       "        603.4, 594.0],\n",
       "       [619.0, 69.0, 37.0, 1017.3, 1, 1, 0, 18.0, 0, 608.3333333333334,\n",
       "        607.4, 612.0],\n",
       "       [615.0, 69.1, 37.0, 1017.2, 1, 1, 0, 18.0, 0, 615.3333333333334,\n",
       "        607.2, 619.0],\n",
       "       [629.0, 69.1, 37.0, 1017.2, 1, 1, 1, 18.0, 0, 621.0, 613.8, 615.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of T after removing columns 2, 3, 6, and 7: (100, 19, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop the first and the last columns from the 3D array X\n",
    "# T = T[:, :, 1:-2]\n",
    "import numpy as np\n",
    "\n",
    "# Assuming T is your 3D NumPy array and has a sufficient number of columns\n",
    "# Calculate the indices of the columns to keep\n",
    "cols_to_keep = [i for i in range(T.shape[2]) if i not in (2, 3, 7, 8)]\n",
    "\n",
    "# Slice the array to keep only the desired columns\n",
    "T = T[:, :, cols_to_keep]\n",
    "\n",
    "print(\"New shape of T after removing columns 2, 3, 6, and 7:\", T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 19, 8)\n",
      "y_train shape: (80,)\n",
      "X_test shape: (20, 19, 8)\n",
      "y_test shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "T = T.astype(np.float64)\n",
    "# Encode labels: 'Song' as 1, 'Chen' as 0\n",
    "y = np.array([1 if label == 'Song' else 0 for label in y])\n",
    "# Scale the features using StandardScaler\n",
    "\n",
    "# Reshape X to 2D array\n",
    "T_2d = T.reshape(-1, T.shape[-1])\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "T_scaled = scaler.fit_transform(T_2d)\n",
    "\n",
    "# Reshape X_scaled back to 3D array\n",
    "T_scaled_3d = T_scaled.reshape(T.shape[0], T.shape[1], T.shape[2])\n",
    "\n",
    "# Split into training and test/validation sets\n",
    "T_train, T_test, y_train, y_test = train_test_split(T_scaled_3d, y, test_size=20, random_state=42, stratify=y)\n",
    "\n",
    "print(\"X_train shape:\", T_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", T_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[19,8]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1086 - loss: 3.2458 - val_accuracy: 0.3500 - val_loss: 2.9542\n",
      "Epoch 2/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3734 - loss: 2.6005 - val_accuracy: 0.6500 - val_loss: 2.2857\n",
      "Epoch 3/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 2.0602 - val_accuracy: 0.7500 - val_loss: 1.7361\n",
      "Epoch 4/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8617 - loss: 1.6471 - val_accuracy: 0.9500 - val_loss: 1.3764\n",
      "Epoch 5/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8797 - loss: 1.3475 - val_accuracy: 0.9500 - val_loss: 1.1607\n",
      "Epoch 6/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9336 - loss: 1.1323 - val_accuracy: 0.9000 - val_loss: 1.0190\n",
      "Epoch 7/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9438 - loss: 0.9743 - val_accuracy: 0.9000 - val_loss: 0.9177\n",
      "Epoch 8/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9438 - loss: 0.8534 - val_accuracy: 0.9000 - val_loss: 0.8407\n",
      "Epoch 9/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.7577 - val_accuracy: 0.9000 - val_loss: 0.7793\n",
      "Epoch 10/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9438 - loss: 0.6799 - val_accuracy: 0.9500 - val_loss: 0.7289\n",
      "Epoch 11/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9438 - loss: 0.6158 - val_accuracy: 0.9500 - val_loss: 0.6867\n",
      "Epoch 12/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.5621 - val_accuracy: 0.9500 - val_loss: 0.6506\n",
      "Epoch 13/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.5165 - val_accuracy: 0.9500 - val_loss: 0.6193\n",
      "Epoch 14/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.4772 - val_accuracy: 0.9500 - val_loss: 0.5919\n",
      "Epoch 15/15\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9438 - loss: 0.4430 - val_accuracy: 0.9500 - val_loss: 0.5678\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(T_train, y_train, epochs=15, validation_data=(T_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 50], ylim=[0, 2], xlabel='Epochs', grid=True,\n",
    "    style=['r', 'r--', 'b', 'b-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9500 - loss: 0.5678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5678000450134277, 0.949999988079071]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(T_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
       "       dtype=int64),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = model.predict(T_test)\n",
    "y_proba.round(2)\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9500\n",
      "Precision: 0.9545\n",
      "Recall: 0.9500\n",
      "F1-score: 0.9499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, average='macro'):\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Return metrics as a dictionary\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1}\n",
    "\n",
    "# Example usage (ensure y_test and y_pred are defined appropriately)\n",
    "metrics = evaluate_classification(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing RNN Sequenceing for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 15, 8)\n",
      "y_train shape: (80, 4, 8)\n",
      "X_test shape: (20, 15, 8)\n",
      "y_test shape: (20, 4, 8)\n"
     ]
    }
   ],
   "source": [
    "# Calculating the split index for 90% of the time steps\n",
    "split_index = int(0.8 * 19)  \n",
    "\n",
    "# Splitting the training data\n",
    "X_train = T_train[:, :split_index, :]\n",
    "y_train = T_train[:, split_index:, :]\n",
    "\n",
    "# Splitting the testing data\n",
    "X_test = T_test[:, :split_index, :]\n",
    "y_test = T_test[:, split_index:, :]\n",
    "\n",
    "# Print shapes to confirm the setup\n",
    "print(\"X_train shape:\", X_train.shape)  \n",
    "print(\"y_train shape:\", y_train.shape)  \n",
    "print(\"X_test shape:\", X_test.shape)    \n",
    "print(\"y_test shape:\", y_test.shape)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 15, 8)\n",
      "y_train shape: (80, 4, 8)\n",
      "X_test shape: (20, 15, 8)\n",
      "y_test shape: (20, 4, 8)\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cld1465\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 1.1187 - mae: 0.7983 - val_loss: 1.8396 - val_mae: 0.9618\n",
      "Epoch 2/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1221 - mae: 0.8005 - val_loss: 1.8261 - val_mae: 0.9592\n",
      "Epoch 3/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1089 - mae: 0.7934 - val_loss: 1.8116 - val_mae: 0.9562\n",
      "Epoch 4/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1041 - mae: 0.7956 - val_loss: 1.8039 - val_mae: 0.9540\n",
      "Epoch 5/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0936 - mae: 0.7902 - val_loss: 1.7966 - val_mae: 0.9520\n",
      "Epoch 6/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0880 - mae: 0.7879 - val_loss: 1.7885 - val_mae: 0.9500\n",
      "Epoch 7/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0810 - mae: 0.7887 - val_loss: 1.7800 - val_mae: 0.9479\n",
      "Epoch 8/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0713 - mae: 0.7831 - val_loss: 1.7721 - val_mae: 0.9460\n",
      "Epoch 9/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0684 - mae: 0.7841 - val_loss: 1.7645 - val_mae: 0.9441\n",
      "Epoch 10/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0571 - mae: 0.7817 - val_loss: 1.7573 - val_mae: 0.9422\n",
      "Epoch 11/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0484 - mae: 0.7781 - val_loss: 1.7502 - val_mae: 0.9402\n",
      "Epoch 12/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0441 - mae: 0.7755 - val_loss: 1.7428 - val_mae: 0.9379\n",
      "Epoch 13/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0399 - mae: 0.7744 - val_loss: 1.7355 - val_mae: 0.9355\n",
      "Epoch 14/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0261 - mae: 0.7695 - val_loss: 1.7280 - val_mae: 0.9328\n",
      "Epoch 15/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0199 - mae: 0.7687 - val_loss: 1.7203 - val_mae: 0.9298\n",
      "Epoch 16/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0133 - mae: 0.7661 - val_loss: 1.7120 - val_mae: 0.9264\n",
      "Epoch 17/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0056 - mae: 0.7598 - val_loss: 1.7031 - val_mae: 0.9226\n",
      "Epoch 18/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0003 - mae: 0.7574 - val_loss: 1.6929 - val_mae: 0.9180\n",
      "Epoch 19/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9911 - mae: 0.7542 - val_loss: 1.6800 - val_mae: 0.9121\n",
      "Epoch 20/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9819 - mae: 0.7481 - val_loss: 1.6652 - val_mae: 0.9047\n",
      "Epoch 21/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9818 - mae: 0.7451 - val_loss: 1.6545 - val_mae: 0.9003\n",
      "Epoch 22/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9706 - mae: 0.7403 - val_loss: 1.6418 - val_mae: 0.8947\n",
      "Epoch 23/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9553 - mae: 0.7361 - val_loss: 1.6267 - val_mae: 0.8876\n",
      "Epoch 24/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9416 - mae: 0.7255 - val_loss: 1.6117 - val_mae: 0.8808\n",
      "Epoch 25/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9212 - mae: 0.7190 - val_loss: 1.5938 - val_mae: 0.8719\n",
      "Epoch 26/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9223 - mae: 0.7149 - val_loss: 1.5738 - val_mae: 0.8610\n",
      "Epoch 27/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9235 - mae: 0.7146 - val_loss: 1.5612 - val_mae: 0.8560\n",
      "Epoch 28/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9034 - mae: 0.7007 - val_loss: 1.5550 - val_mae: 0.8564\n",
      "Epoch 29/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8940 - mae: 0.7065 - val_loss: 1.5444 - val_mae: 0.8528\n",
      "Epoch 30/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8866 - mae: 0.6990 - val_loss: 1.5282 - val_mae: 0.8448\n",
      "Epoch 31/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8748 - mae: 0.6935 - val_loss: 1.5080 - val_mae: 0.8335\n",
      "Epoch 32/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8619 - mae: 0.6801 - val_loss: 1.4857 - val_mae: 0.8196\n",
      "Epoch 33/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8516 - mae: 0.6766 - val_loss: 1.4629 - val_mae: 0.8045\n",
      "Epoch 34/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8677 - mae: 0.6867 - val_loss: 1.4492 - val_mae: 0.7986\n",
      "Epoch 35/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8373 - mae: 0.6711 - val_loss: 1.4365 - val_mae: 0.7941\n",
      "Epoch 36/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8315 - mae: 0.6624 - val_loss: 1.4224 - val_mae: 0.7879\n",
      "Epoch 37/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8210 - mae: 0.6619 - val_loss: 1.4049 - val_mae: 0.7781\n",
      "Epoch 38/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8165 - mae: 0.6562 - val_loss: 1.3923 - val_mae: 0.7731\n",
      "Epoch 39/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7954 - mae: 0.6392 - val_loss: 1.3784 - val_mae: 0.7672\n",
      "Epoch 40/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7952 - mae: 0.6422 - val_loss: 1.3640 - val_mae: 0.7611\n",
      "Epoch 41/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7853 - mae: 0.6363 - val_loss: 1.3473 - val_mae: 0.7538\n",
      "Epoch 42/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7690 - mae: 0.6192 - val_loss: 1.3300 - val_mae: 0.7459\n",
      "Epoch 43/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7684 - mae: 0.6320 - val_loss: 1.3128 - val_mae: 0.7384\n",
      "Epoch 44/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7534 - mae: 0.6189 - val_loss: 1.2938 - val_mae: 0.7291\n",
      "Epoch 45/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7686 - mae: 0.6364 - val_loss: 1.2735 - val_mae: 0.7189\n",
      "Epoch 46/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7402 - mae: 0.6133 - val_loss: 1.2549 - val_mae: 0.7121\n",
      "Epoch 47/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7336 - mae: 0.6056 - val_loss: 1.2406 - val_mae: 0.7108\n",
      "Epoch 48/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7293 - mae: 0.6017 - val_loss: 1.2262 - val_mae: 0.7093\n",
      "Epoch 49/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7249 - mae: 0.5997 - val_loss: 1.2112 - val_mae: 0.7063\n",
      "Epoch 50/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7198 - mae: 0.6001 - val_loss: 1.1947 - val_mae: 0.7005\n",
      "Epoch 51/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7070 - mae: 0.5916 - val_loss: 1.1784 - val_mae: 0.6950\n",
      "Epoch 52/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6993 - mae: 0.5902 - val_loss: 1.1579 - val_mae: 0.6869\n",
      "Epoch 53/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7040 - mae: 0.5955 - val_loss: 1.1359 - val_mae: 0.6784\n",
      "Epoch 54/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6949 - mae: 0.5834 - val_loss: 1.1130 - val_mae: 0.6696\n",
      "Epoch 55/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6787 - mae: 0.5727 - val_loss: 1.0881 - val_mae: 0.6610\n",
      "Epoch 56/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6787 - mae: 0.5762 - val_loss: 1.0631 - val_mae: 0.6530\n",
      "Epoch 57/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6794 - mae: 0.5717 - val_loss: 1.0395 - val_mae: 0.6469\n",
      "Epoch 58/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6817 - mae: 0.5769 - val_loss: 1.0220 - val_mae: 0.6440\n",
      "Epoch 59/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6723 - mae: 0.5824 - val_loss: 1.0039 - val_mae: 0.6394\n",
      "Epoch 60/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6566 - mae: 0.5694 - val_loss: 0.9860 - val_mae: 0.6344\n",
      "Epoch 61/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6617 - mae: 0.5817 - val_loss: 0.9650 - val_mae: 0.6280\n",
      "Epoch 62/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6288 - mae: 0.5452 - val_loss: 0.9407 - val_mae: 0.6206\n",
      "Epoch 63/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6282 - mae: 0.5496 - val_loss: 0.9192 - val_mae: 0.6150\n",
      "Epoch 64/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6375 - mae: 0.5653 - val_loss: 0.8955 - val_mae: 0.6077\n",
      "Epoch 65/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6379 - mae: 0.5631 - val_loss: 0.8734 - val_mae: 0.6006\n",
      "Epoch 66/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6084 - mae: 0.5408 - val_loss: 0.8557 - val_mae: 0.5951\n",
      "Epoch 67/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6138 - mae: 0.5330 - val_loss: 0.8416 - val_mae: 0.5908\n",
      "Epoch 68/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6338 - mae: 0.5544 - val_loss: 0.8328 - val_mae: 0.5873\n",
      "Epoch 69/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5898 - mae: 0.5291 - val_loss: 0.8235 - val_mae: 0.5841\n",
      "Epoch 70/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5895 - mae: 0.5355 - val_loss: 0.8091 - val_mae: 0.5795\n",
      "Epoch 71/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6066 - mae: 0.5460 - val_loss: 0.7910 - val_mae: 0.5726\n",
      "Epoch 72/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5816 - mae: 0.5266 - val_loss: 0.7755 - val_mae: 0.5663\n",
      "Epoch 73/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5919 - mae: 0.5298 - val_loss: 0.7664 - val_mae: 0.5620\n",
      "Epoch 74/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5852 - mae: 0.5245 - val_loss: 0.7611 - val_mae: 0.5596\n",
      "Epoch 75/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5546 - mae: 0.5128 - val_loss: 0.7521 - val_mae: 0.5562\n",
      "Epoch 76/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6018 - mae: 0.5295 - val_loss: 0.7440 - val_mae: 0.5543\n",
      "Epoch 77/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5779 - mae: 0.5310 - val_loss: 0.7299 - val_mae: 0.5493\n",
      "Epoch 78/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5776 - mae: 0.5235 - val_loss: 0.7212 - val_mae: 0.5459\n",
      "Epoch 79/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5691 - mae: 0.5227 - val_loss: 0.7133 - val_mae: 0.5424\n",
      "Epoch 80/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5461 - mae: 0.5075 - val_loss: 0.7068 - val_mae: 0.5394\n",
      "Epoch 81/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5654 - mae: 0.5164 - val_loss: 0.7116 - val_mae: 0.5413\n",
      "Epoch 82/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5669 - mae: 0.5169 - val_loss: 0.7189 - val_mae: 0.5435\n",
      "Epoch 83/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5447 - mae: 0.5090 - val_loss: 0.7282 - val_mae: 0.5469\n",
      "Epoch 84/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5652 - mae: 0.5239 - val_loss: 0.7312 - val_mae: 0.5475\n",
      "Epoch 85/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5657 - mae: 0.5178 - val_loss: 0.7338 - val_mae: 0.5459\n",
      "Epoch 86/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5498 - mae: 0.5054 - val_loss: 0.7296 - val_mae: 0.5411\n",
      "Epoch 87/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5323 - mae: 0.5042 - val_loss: 0.7254 - val_mae: 0.5350\n",
      "Epoch 88/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5377 - mae: 0.5000 - val_loss: 0.7218 - val_mae: 0.5297\n",
      "Epoch 89/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5355 - mae: 0.4991 - val_loss: 0.7195 - val_mae: 0.5263\n",
      "Epoch 90/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5209 - mae: 0.4899 - val_loss: 0.7198 - val_mae: 0.5255\n",
      "Epoch 91/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5274 - mae: 0.4996 - val_loss: 0.7194 - val_mae: 0.5252\n",
      "Epoch 92/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5399 - mae: 0.5148 - val_loss: 0.7007 - val_mae: 0.5201\n",
      "Epoch 93/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5256 - mae: 0.4900 - val_loss: 0.6974 - val_mae: 0.5205\n",
      "Epoch 94/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5050 - mae: 0.4831 - val_loss: 0.6991 - val_mae: 0.5213\n",
      "Epoch 95/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5098 - mae: 0.4733 - val_loss: 0.6901 - val_mae: 0.5178\n",
      "Epoch 96/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5093 - mae: 0.4837 - val_loss: 0.6796 - val_mae: 0.5153\n",
      "Epoch 97/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5350 - mae: 0.4974 - val_loss: 0.6665 - val_mae: 0.5118\n",
      "Epoch 98/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5112 - mae: 0.4849 - val_loss: 0.6425 - val_mae: 0.5045\n",
      "Epoch 99/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5184 - mae: 0.4816 - val_loss: 0.6401 - val_mae: 0.5052\n",
      "Epoch 100/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5022 - mae: 0.4844 - val_loss: 0.6405 - val_mae: 0.5056\n",
      "Epoch 101/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5204 - mae: 0.4846 - val_loss: 0.6481 - val_mae: 0.5083\n",
      "Epoch 102/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5030 - mae: 0.4703 - val_loss: 0.6551 - val_mae: 0.5118\n",
      "Epoch 103/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5109 - mae: 0.4864 - val_loss: 0.6622 - val_mae: 0.5152\n",
      "Epoch 104/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5015 - mae: 0.4806 - val_loss: 0.6707 - val_mae: 0.5186\n",
      "Epoch 105/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4906 - mae: 0.4775 - val_loss: 0.6761 - val_mae: 0.5184\n",
      "Epoch 106/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5192 - mae: 0.4847 - val_loss: 0.6866 - val_mae: 0.5174\n",
      "Epoch 107/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4959 - mae: 0.4749 - val_loss: 0.7019 - val_mae: 0.5162\n",
      "Epoch 108/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5111 - mae: 0.4734 - val_loss: 0.7152 - val_mae: 0.5167\n",
      "Epoch 109/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4831 - mae: 0.4735 - val_loss: 0.7264 - val_mae: 0.5156\n",
      "Epoch 110/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4721 - mae: 0.4663 - val_loss: 0.7461 - val_mae: 0.5170\n",
      "Epoch 111/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4896 - mae: 0.4703 - val_loss: 0.7874 - val_mae: 0.5248\n",
      "Epoch 112/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4750 - mae: 0.4646 - val_loss: 0.8203 - val_mae: 0.5308\n",
      "Epoch 113/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4886 - mae: 0.4711 - val_loss: 0.8251 - val_mae: 0.5305\n",
      "Epoch 114/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4691 - mae: 0.4595 - val_loss: 0.8438 - val_mae: 0.5317\n",
      "Epoch 115/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4641 - mae: 0.4586 - val_loss: 0.8872 - val_mae: 0.5386\n",
      "Epoch 116/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4672 - mae: 0.4643 - val_loss: 0.9285 - val_mae: 0.5458\n",
      "Epoch 117/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4607 - mae: 0.4554 - val_loss: 0.9616 - val_mae: 0.5501\n",
      "Epoch 118/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4793 - mae: 0.4673 - val_loss: 0.9892 - val_mae: 0.5525\n",
      "Epoch 119/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4821 - mae: 0.4725 - val_loss: 1.0051 - val_mae: 0.5534\n",
      "Epoch 120/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4866 - mae: 0.4757 - val_loss: 0.9898 - val_mae: 0.5523\n",
      "Epoch 121/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4554 - mae: 0.4566 - val_loss: 0.8894 - val_mae: 0.5398\n",
      "Epoch 122/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4893 - mae: 0.4804 - val_loss: 0.7953 - val_mae: 0.5259\n",
      "Epoch 123/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4513 - mae: 0.4550 - val_loss: 0.7306 - val_mae: 0.5151\n",
      "Epoch 124/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4552 - mae: 0.4579 - val_loss: 0.7002 - val_mae: 0.5092\n",
      "Epoch 125/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4647 - mae: 0.4673 - val_loss: 0.6777 - val_mae: 0.5025\n",
      "Epoch 126/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4601 - mae: 0.4558 - val_loss: 0.6314 - val_mae: 0.4899\n",
      "Epoch 127/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4662 - mae: 0.4505 - val_loss: 0.6092 - val_mae: 0.4845\n",
      "Epoch 128/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4733 - mae: 0.4571 - val_loss: 0.6007 - val_mae: 0.4830\n",
      "Epoch 129/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4310 - mae: 0.4416 - val_loss: 0.5993 - val_mae: 0.4831\n",
      "Epoch 130/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4476 - mae: 0.4505 - val_loss: 0.5897 - val_mae: 0.4798\n",
      "Epoch 131/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4566 - mae: 0.4566 - val_loss: 0.5804 - val_mae: 0.4749\n",
      "Epoch 132/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4438 - mae: 0.4584 - val_loss: 0.5797 - val_mae: 0.4732\n",
      "Epoch 133/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4660 - mae: 0.4590 - val_loss: 0.5839 - val_mae: 0.4744\n",
      "Epoch 134/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4497 - mae: 0.4525 - val_loss: 0.5893 - val_mae: 0.4764\n",
      "Epoch 135/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4450 - mae: 0.4504 - val_loss: 0.5929 - val_mae: 0.4766\n",
      "Epoch 136/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4580 - mae: 0.4605 - val_loss: 0.5940 - val_mae: 0.4756\n",
      "Epoch 137/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4470 - mae: 0.4443 - val_loss: 0.5995 - val_mae: 0.4783\n",
      "Epoch 138/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4411 - mae: 0.4530 - val_loss: 0.6097 - val_mae: 0.4811\n",
      "Epoch 139/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4532 - mae: 0.4577 - val_loss: 0.6150 - val_mae: 0.4795\n",
      "Epoch 140/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4371 - mae: 0.4461 - val_loss: 0.6314 - val_mae: 0.4805\n",
      "Epoch 141/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4299 - mae: 0.4488 - val_loss: 0.6516 - val_mae: 0.4826\n",
      "Epoch 142/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4343 - mae: 0.4482 - val_loss: 0.6667 - val_mae: 0.4850\n",
      "Epoch 143/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4271 - mae: 0.4377 - val_loss: 0.6860 - val_mae: 0.4873\n",
      "Epoch 144/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4208 - mae: 0.4335 - val_loss: 0.6893 - val_mae: 0.4853\n",
      "Epoch 145/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4365 - mae: 0.4495 - val_loss: 0.7454 - val_mae: 0.4935\n",
      "Epoch 146/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4277 - mae: 0.4426 - val_loss: 0.7686 - val_mae: 0.4976\n",
      "Epoch 147/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4327 - mae: 0.4404 - val_loss: 0.7978 - val_mae: 0.5049\n",
      "Epoch 148/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4281 - mae: 0.4388 - val_loss: 0.8215 - val_mae: 0.5123\n",
      "Epoch 149/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4053 - mae: 0.4261 - val_loss: 0.8402 - val_mae: 0.5166\n",
      "Epoch 150/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4057 - mae: 0.4190 - val_loss: 0.8487 - val_mae: 0.5171\n",
      "Epoch 151/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4362 - mae: 0.4445 - val_loss: 0.8651 - val_mae: 0.5185\n",
      "Epoch 152/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4076 - mae: 0.4315 - val_loss: 0.7570 - val_mae: 0.5017\n",
      "Epoch 153/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4038 - mae: 0.4227 - val_loss: 0.6821 - val_mae: 0.4890\n",
      "Epoch 154/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4160 - mae: 0.4337 - val_loss: 0.6270 - val_mae: 0.4777\n",
      "Epoch 155/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4000 - mae: 0.4186 - val_loss: 0.5911 - val_mae: 0.4698\n",
      "Epoch 156/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4276 - mae: 0.4365 - val_loss: 0.5740 - val_mae: 0.4665\n",
      "Epoch 157/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4043 - mae: 0.4265 - val_loss: 0.5665 - val_mae: 0.4620\n",
      "Epoch 158/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4210 - mae: 0.4306 - val_loss: 0.5583 - val_mae: 0.4568\n",
      "Epoch 159/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3955 - mae: 0.4226 - val_loss: 0.5506 - val_mae: 0.4524\n",
      "Epoch 160/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4274 - mae: 0.4407 - val_loss: 0.5490 - val_mae: 0.4497\n",
      "Epoch 161/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4037 - mae: 0.4313 - val_loss: 0.5445 - val_mae: 0.4470\n",
      "Epoch 162/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4342 - mae: 0.4444 - val_loss: 0.5466 - val_mae: 0.4483\n",
      "Epoch 163/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3831 - mae: 0.4113 - val_loss: 0.5499 - val_mae: 0.4518\n",
      "Epoch 164/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4153 - mae: 0.4325 - val_loss: 0.5547 - val_mae: 0.4575\n",
      "Epoch 165/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4168 - mae: 0.4390 - val_loss: 0.5612 - val_mae: 0.4638\n",
      "Epoch 166/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4409 - mae: 0.4525 - val_loss: 0.5670 - val_mae: 0.4680\n",
      "Epoch 167/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4096 - mae: 0.4308 - val_loss: 0.5612 - val_mae: 0.4664\n",
      "Epoch 168/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4050 - mae: 0.4341 - val_loss: 0.5558 - val_mae: 0.4634\n",
      "Epoch 169/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3949 - mae: 0.4239 - val_loss: 0.5471 - val_mae: 0.4561\n",
      "Epoch 170/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3931 - mae: 0.4176 - val_loss: 0.5302 - val_mae: 0.4464\n",
      "Epoch 171/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3746 - mae: 0.4061 - val_loss: 0.5201 - val_mae: 0.4419\n",
      "Epoch 172/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3889 - mae: 0.4204 - val_loss: 0.5329 - val_mae: 0.4477\n",
      "Epoch 173/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3755 - mae: 0.4189 - val_loss: 0.5340 - val_mae: 0.4495\n",
      "Epoch 174/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3794 - mae: 0.4076 - val_loss: 0.5341 - val_mae: 0.4509\n",
      "Epoch 175/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4025 - mae: 0.4261 - val_loss: 0.5370 - val_mae: 0.4540\n",
      "Epoch 176/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4058 - mae: 0.4408 - val_loss: 0.5348 - val_mae: 0.4520\n",
      "Epoch 177/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3795 - mae: 0.4112 - val_loss: 0.5322 - val_mae: 0.4494\n",
      "Epoch 178/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3891 - mae: 0.4130 - val_loss: 0.5269 - val_mae: 0.4463\n",
      "Epoch 179/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3866 - mae: 0.4188 - val_loss: 0.5149 - val_mae: 0.4391\n",
      "Epoch 180/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3681 - mae: 0.4090 - val_loss: 0.5031 - val_mae: 0.4308\n",
      "Epoch 181/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3754 - mae: 0.4103 - val_loss: 0.4975 - val_mae: 0.4272\n",
      "Epoch 182/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3707 - mae: 0.4007 - val_loss: 0.5011 - val_mae: 0.4286\n",
      "Epoch 183/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3811 - mae: 0.4095 - val_loss: 0.5060 - val_mae: 0.4316\n",
      "Epoch 184/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3900 - mae: 0.4175 - val_loss: 0.5290 - val_mae: 0.4408\n",
      "Epoch 185/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3731 - mae: 0.4024 - val_loss: 0.5631 - val_mae: 0.4526\n",
      "Epoch 186/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3781 - mae: 0.4111 - val_loss: 0.5950 - val_mae: 0.4621\n",
      "Epoch 187/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3941 - mae: 0.4199 - val_loss: 0.6159 - val_mae: 0.4661\n",
      "Epoch 188/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3662 - mae: 0.4053 - val_loss: 0.6304 - val_mae: 0.4655\n",
      "Epoch 189/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3496 - mae: 0.3913 - val_loss: 0.6228 - val_mae: 0.4611\n",
      "Epoch 190/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3932 - mae: 0.4187 - val_loss: 0.6289 - val_mae: 0.4599\n",
      "Epoch 191/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4023 - mae: 0.4213 - val_loss: 0.6267 - val_mae: 0.4594\n",
      "Epoch 192/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4024 - mae: 0.4224 - val_loss: 0.6447 - val_mae: 0.4633\n",
      "Epoch 193/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3697 - mae: 0.3996 - val_loss: 0.6781 - val_mae: 0.4700\n",
      "Epoch 194/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3773 - mae: 0.4103 - val_loss: 0.7056 - val_mae: 0.4736\n",
      "Epoch 195/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3750 - mae: 0.3957 - val_loss: 0.7372 - val_mae: 0.4769\n",
      "Epoch 196/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3731 - mae: 0.3986 - val_loss: 0.7677 - val_mae: 0.4811\n",
      "Epoch 197/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3649 - mae: 0.4090 - val_loss: 0.7828 - val_mae: 0.4816\n",
      "Epoch 198/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3724 - mae: 0.4081 - val_loss: 0.7878 - val_mae: 0.4803\n",
      "Epoch 199/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3713 - mae: 0.4032 - val_loss: 0.8146 - val_mae: 0.4826\n",
      "Epoch 200/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3402 - mae: 0.3904 - val_loss: 0.8246 - val_mae: 0.4827\n",
      "Epoch 201/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3617 - mae: 0.3997 - val_loss: 0.8119 - val_mae: 0.4796\n",
      "Epoch 202/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3623 - mae: 0.3939 - val_loss: 0.8273 - val_mae: 0.4806\n",
      "Epoch 203/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3556 - mae: 0.3870 - val_loss: 0.8199 - val_mae: 0.4808\n",
      "Epoch 204/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3527 - mae: 0.3955 - val_loss: 0.8194 - val_mae: 0.4852\n",
      "Epoch 205/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3728 - mae: 0.4016 - val_loss: 0.8198 - val_mae: 0.4854\n",
      "Epoch 206/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3664 - mae: 0.4067 - val_loss: 0.7741 - val_mae: 0.4794\n",
      "Epoch 207/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3367 - mae: 0.3860 - val_loss: 0.7204 - val_mae: 0.4710\n",
      "Epoch 208/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3720 - mae: 0.3984 - val_loss: 0.6671 - val_mae: 0.4619\n",
      "Epoch 209/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3760 - mae: 0.4019 - val_loss: 0.6511 - val_mae: 0.4578\n",
      "Epoch 210/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3803 - mae: 0.4133 - val_loss: 0.6937 - val_mae: 0.4616\n",
      "Epoch 211/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3638 - mae: 0.3921 - val_loss: 0.7553 - val_mae: 0.4688\n",
      "Epoch 212/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3519 - mae: 0.3936 - val_loss: 0.7192 - val_mae: 0.4630\n",
      "Epoch 213/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3254 - mae: 0.3699 - val_loss: 0.7447 - val_mae: 0.4705\n",
      "Epoch 214/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3421 - mae: 0.3884 - val_loss: 0.7495 - val_mae: 0.4754\n",
      "Epoch 215/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3710 - mae: 0.4039 - val_loss: 0.7507 - val_mae: 0.4784\n",
      "Epoch 216/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3763 - mae: 0.4099 - val_loss: 0.7404 - val_mae: 0.4753\n",
      "Epoch 217/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3284 - mae: 0.3785 - val_loss: 0.7302 - val_mae: 0.4725\n",
      "Epoch 218/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3564 - mae: 0.3922 - val_loss: 0.7000 - val_mae: 0.4676\n",
      "Epoch 219/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3682 - mae: 0.3970 - val_loss: 0.6459 - val_mae: 0.4584\n",
      "Epoch 220/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3552 - mae: 0.3981 - val_loss: 0.6072 - val_mae: 0.4509\n",
      "Epoch 221/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3772 - mae: 0.4087 - val_loss: 0.5892 - val_mae: 0.4495\n",
      "Epoch 222/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3331 - mae: 0.3873 - val_loss: 0.5744 - val_mae: 0.4463\n",
      "Epoch 223/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3393 - mae: 0.3809 - val_loss: 0.5499 - val_mae: 0.4402\n",
      "Epoch 224/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3313 - mae: 0.3771 - val_loss: 0.5291 - val_mae: 0.4324\n",
      "Epoch 225/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3568 - mae: 0.3912 - val_loss: 0.5269 - val_mae: 0.4301\n",
      "Epoch 226/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3836 - mae: 0.4110 - val_loss: 0.5325 - val_mae: 0.4323\n",
      "Epoch 227/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3579 - mae: 0.3982 - val_loss: 0.5741 - val_mae: 0.4421\n",
      "Epoch 228/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3453 - mae: 0.3898 - val_loss: 0.6306 - val_mae: 0.4522\n",
      "Epoch 229/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3872 - mae: 0.4209 - val_loss: 0.6994 - val_mae: 0.4622\n",
      "Epoch 230/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3334 - mae: 0.3794 - val_loss: 0.7507 - val_mae: 0.4692\n",
      "Epoch 231/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3340 - mae: 0.3721 - val_loss: 0.7818 - val_mae: 0.4747\n",
      "Epoch 232/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3518 - mae: 0.3971 - val_loss: 0.6619 - val_mae: 0.4541\n",
      "Epoch 233/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3649 - mae: 0.3962 - val_loss: 0.5290 - val_mae: 0.4248\n",
      "Epoch 234/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3540 - mae: 0.3878 - val_loss: 0.4654 - val_mae: 0.4073\n",
      "Epoch 235/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3296 - mae: 0.3645 - val_loss: 0.4512 - val_mae: 0.4055\n",
      "Epoch 236/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3628 - mae: 0.4000 - val_loss: 0.4438 - val_mae: 0.4041\n",
      "Epoch 237/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3303 - mae: 0.3862 - val_loss: 0.4282 - val_mae: 0.3974\n",
      "Epoch 238/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3198 - mae: 0.3741 - val_loss: 0.4182 - val_mae: 0.3936\n",
      "Epoch 239/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3254 - mae: 0.3741 - val_loss: 0.4165 - val_mae: 0.3935\n",
      "Epoch 240/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3690 - mae: 0.4035 - val_loss: 0.4220 - val_mae: 0.3973\n",
      "Epoch 241/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3405 - mae: 0.3834 - val_loss: 0.4325 - val_mae: 0.4000\n",
      "Epoch 242/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3376 - mae: 0.3786 - val_loss: 0.4508 - val_mae: 0.4079\n",
      "Epoch 243/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3309 - mae: 0.3826 - val_loss: 0.4561 - val_mae: 0.4097\n",
      "Epoch 244/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3137 - mae: 0.3700 - val_loss: 0.4322 - val_mae: 0.3977\n",
      "Epoch 245/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3702 - mae: 0.3938 - val_loss: 0.4098 - val_mae: 0.3915\n",
      "Epoch 246/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3579 - mae: 0.3979 - val_loss: 0.4002 - val_mae: 0.3876\n",
      "Epoch 247/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3266 - mae: 0.3751 - val_loss: 0.3993 - val_mae: 0.3846\n",
      "Epoch 248/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3237 - mae: 0.3817 - val_loss: 0.4086 - val_mae: 0.3887\n",
      "Epoch 249/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3394 - mae: 0.3790 - val_loss: 0.4192 - val_mae: 0.3941\n",
      "Epoch 250/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3757 - mae: 0.4066 - val_loss: 0.4332 - val_mae: 0.4003\n",
      "Epoch 251/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3420 - mae: 0.3874 - val_loss: 0.4444 - val_mae: 0.4039\n",
      "Epoch 252/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3084 - mae: 0.3642 - val_loss: 0.4444 - val_mae: 0.4045\n",
      "Epoch 253/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3373 - mae: 0.3767 - val_loss: 0.4342 - val_mae: 0.4024\n",
      "Epoch 254/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3218 - mae: 0.3833 - val_loss: 0.4204 - val_mae: 0.3946\n",
      "Epoch 255/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3440 - mae: 0.3796 - val_loss: 0.4159 - val_mae: 0.3899\n",
      "Epoch 256/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3459 - mae: 0.3793 - val_loss: 0.4166 - val_mae: 0.3861\n",
      "Epoch 257/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3087 - mae: 0.3685 - val_loss: 0.4217 - val_mae: 0.3887\n",
      "Epoch 258/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3039 - mae: 0.3538 - val_loss: 0.4181 - val_mae: 0.3877\n",
      "Epoch 259/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3161 - mae: 0.3737 - val_loss: 0.4131 - val_mae: 0.3855\n",
      "Epoch 260/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3147 - mae: 0.3682 - val_loss: 0.4125 - val_mae: 0.4004\n",
      "Epoch 261/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3333 - mae: 0.3974 - val_loss: 0.4080 - val_mae: 0.3953\n",
      "Epoch 262/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3140 - mae: 0.3757 - val_loss: 0.4109 - val_mae: 0.3868\n",
      "Epoch 263/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3146 - mae: 0.3675 - val_loss: 0.4310 - val_mae: 0.4011\n",
      "Epoch 264/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3146 - mae: 0.3725 - val_loss: 0.4320 - val_mae: 0.3980\n",
      "Epoch 265/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3528 - mae: 0.3934 - val_loss: 0.4210 - val_mae: 0.3890\n",
      "Epoch 266/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3112 - mae: 0.3590 - val_loss: 0.4165 - val_mae: 0.3877\n",
      "Epoch 267/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3017 - mae: 0.3566 - val_loss: 0.4135 - val_mae: 0.3819\n",
      "Epoch 268/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3251 - mae: 0.3660 - val_loss: 0.4129 - val_mae: 0.3799\n",
      "Epoch 269/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3293 - mae: 0.3690 - val_loss: 0.4166 - val_mae: 0.3813\n",
      "Epoch 270/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3339 - mae: 0.3754 - val_loss: 0.4394 - val_mae: 0.3920\n",
      "Epoch 271/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3273 - mae: 0.3825 - val_loss: 0.4432 - val_mae: 0.3929\n",
      "Epoch 272/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3197 - mae: 0.3764 - val_loss: 0.4448 - val_mae: 0.3943\n",
      "Epoch 273/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3242 - mae: 0.3623 - val_loss: 0.4471 - val_mae: 0.3940\n",
      "Epoch 274/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2980 - mae: 0.3542 - val_loss: 0.4494 - val_mae: 0.3967\n",
      "Epoch 275/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3151 - mae: 0.3661 - val_loss: 0.4289 - val_mae: 0.3903\n",
      "Epoch 276/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3299 - mae: 0.3775 - val_loss: 0.4065 - val_mae: 0.3822\n",
      "Epoch 277/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3102 - mae: 0.3594 - val_loss: 0.3927 - val_mae: 0.3774\n",
      "Epoch 278/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3358 - mae: 0.3706 - val_loss: 0.3850 - val_mae: 0.3722\n",
      "Epoch 279/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3063 - mae: 0.3536 - val_loss: 0.3840 - val_mae: 0.3711\n",
      "Epoch 280/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3186 - mae: 0.3643 - val_loss: 0.3886 - val_mae: 0.3749\n",
      "Epoch 281/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3002 - mae: 0.3520 - val_loss: 0.3978 - val_mae: 0.3803\n",
      "Epoch 282/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3063 - mae: 0.3618 - val_loss: 0.4069 - val_mae: 0.3835\n",
      "Epoch 283/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2889 - mae: 0.3464 - val_loss: 0.4151 - val_mae: 0.3869\n",
      "Epoch 284/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3077 - mae: 0.3573 - val_loss: 0.4187 - val_mae: 0.3884\n",
      "Epoch 285/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3202 - mae: 0.3729 - val_loss: 0.4189 - val_mae: 0.3856\n",
      "Epoch 286/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2914 - mae: 0.3527 - val_loss: 0.4236 - val_mae: 0.3873\n",
      "Epoch 287/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2914 - mae: 0.3623 - val_loss: 0.4069 - val_mae: 0.3782\n",
      "Epoch 288/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3071 - mae: 0.3575 - val_loss: 0.3895 - val_mae: 0.3700\n",
      "Epoch 289/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3025 - mae: 0.3447 - val_loss: 0.3895 - val_mae: 0.3742\n",
      "Epoch 290/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3269 - mae: 0.3748 - val_loss: 0.3865 - val_mae: 0.3680\n",
      "Epoch 291/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3181 - mae: 0.3576 - val_loss: 0.3913 - val_mae: 0.3690\n",
      "Epoch 292/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3084 - mae: 0.3550 - val_loss: 0.4090 - val_mae: 0.3768\n",
      "Epoch 293/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2860 - mae: 0.3464 - val_loss: 0.4174 - val_mae: 0.3826\n",
      "Epoch 294/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3040 - mae: 0.3638 - val_loss: 0.4264 - val_mae: 0.3857\n",
      "Epoch 295/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2853 - mae: 0.3456 - val_loss: 0.4255 - val_mae: 0.3855\n",
      "Epoch 296/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3133 - mae: 0.3607 - val_loss: 0.4066 - val_mae: 0.3777\n",
      "Epoch 297/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2971 - mae: 0.3562 - val_loss: 0.3931 - val_mae: 0.3710\n",
      "Epoch 298/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3057 - mae: 0.3556 - val_loss: 0.3882 - val_mae: 0.3684\n",
      "Epoch 299/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2934 - mae: 0.3449 - val_loss: 0.3872 - val_mae: 0.3708\n",
      "Epoch 300/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3046 - mae: 0.3501 - val_loss: 0.3807 - val_mae: 0.3701\n",
      "Epoch 301/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2829 - mae: 0.3397 - val_loss: 0.3754 - val_mae: 0.3686\n",
      "Epoch 302/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3326 - mae: 0.3626 - val_loss: 0.3837 - val_mae: 0.3745\n",
      "Epoch 303/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3369 - mae: 0.3813 - val_loss: 0.3890 - val_mae: 0.3758\n",
      "Epoch 304/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3147 - mae: 0.3653 - val_loss: 0.3923 - val_mae: 0.3755\n",
      "Epoch 305/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3152 - mae: 0.3710 - val_loss: 0.4018 - val_mae: 0.3770\n",
      "Epoch 306/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2764 - mae: 0.3439 - val_loss: 0.3923 - val_mae: 0.3712\n",
      "Epoch 307/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2613 - mae: 0.3200 - val_loss: 0.3842 - val_mae: 0.3657\n",
      "Epoch 308/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2843 - mae: 0.3370 - val_loss: 0.3893 - val_mae: 0.3639\n",
      "Epoch 309/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2890 - mae: 0.3467 - val_loss: 0.3980 - val_mae: 0.3646\n",
      "Epoch 310/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2712 - mae: 0.3415 - val_loss: 0.4218 - val_mae: 0.3714\n",
      "Epoch 311/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2947 - mae: 0.3490 - val_loss: 0.4389 - val_mae: 0.3828\n",
      "Epoch 312/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2836 - mae: 0.3435 - val_loss: 0.4293 - val_mae: 0.3791\n",
      "Epoch 313/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2860 - mae: 0.3416 - val_loss: 0.4214 - val_mae: 0.3804\n",
      "Epoch 314/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2841 - mae: 0.3520 - val_loss: 0.3908 - val_mae: 0.3704\n",
      "Epoch 315/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2904 - mae: 0.3500 - val_loss: 0.3714 - val_mae: 0.3627\n",
      "Epoch 316/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3031 - mae: 0.3558 - val_loss: 0.3608 - val_mae: 0.3582\n",
      "Epoch 317/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2801 - mae: 0.3401 - val_loss: 0.3644 - val_mae: 0.3571\n",
      "Epoch 318/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2800 - mae: 0.3383 - val_loss: 0.3922 - val_mae: 0.3716\n",
      "Epoch 319/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2687 - mae: 0.3394 - val_loss: 0.3885 - val_mae: 0.3705\n",
      "Epoch 320/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2846 - mae: 0.3454 - val_loss: 0.3693 - val_mae: 0.3654\n",
      "Epoch 321/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2588 - mae: 0.3273 - val_loss: 0.3616 - val_mae: 0.3651\n",
      "Epoch 322/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2792 - mae: 0.3441 - val_loss: 0.3580 - val_mae: 0.3582\n",
      "Epoch 323/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3018 - mae: 0.3507 - val_loss: 0.3773 - val_mae: 0.3640\n",
      "Epoch 324/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2808 - mae: 0.3387 - val_loss: 0.4063 - val_mae: 0.3742\n",
      "Epoch 325/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3285 - mae: 0.3569 - val_loss: 0.4173 - val_mae: 0.3821\n",
      "Epoch 326/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2565 - mae: 0.3226 - val_loss: 0.4083 - val_mae: 0.3813\n",
      "Epoch 327/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2882 - mae: 0.3534 - val_loss: 0.3936 - val_mae: 0.3732\n",
      "Epoch 328/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2986 - mae: 0.3548 - val_loss: 0.3877 - val_mae: 0.3663\n",
      "Epoch 329/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2744 - mae: 0.3320 - val_loss: 0.3838 - val_mae: 0.3666\n",
      "Epoch 330/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2949 - mae: 0.3526 - val_loss: 0.3676 - val_mae: 0.3559\n",
      "Epoch 331/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2505 - mae: 0.3194 - val_loss: 0.3567 - val_mae: 0.3533\n",
      "Epoch 332/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2721 - mae: 0.3299 - val_loss: 0.3539 - val_mae: 0.3560\n",
      "Epoch 333/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2941 - mae: 0.3320 - val_loss: 0.3589 - val_mae: 0.3585\n",
      "Epoch 334/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3047 - mae: 0.3457 - val_loss: 0.3712 - val_mae: 0.3645\n",
      "Epoch 335/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2824 - mae: 0.3400 - val_loss: 0.3776 - val_mae: 0.3686\n",
      "Epoch 336/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2942 - mae: 0.3467 - val_loss: 0.3707 - val_mae: 0.3630\n",
      "Epoch 337/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2597 - mae: 0.3305 - val_loss: 0.3540 - val_mae: 0.3530\n",
      "Epoch 338/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2713 - mae: 0.3347 - val_loss: 0.3495 - val_mae: 0.3512\n",
      "Epoch 339/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3088 - mae: 0.3488 - val_loss: 0.3592 - val_mae: 0.3553\n",
      "Epoch 340/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3250 - mae: 0.3582 - val_loss: 0.3773 - val_mae: 0.3640\n",
      "Epoch 341/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3083 - mae: 0.3537 - val_loss: 0.3841 - val_mae: 0.3664\n",
      "Epoch 342/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2943 - mae: 0.3470 - val_loss: 0.3838 - val_mae: 0.3671\n",
      "Epoch 343/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2806 - mae: 0.3465 - val_loss: 0.3618 - val_mae: 0.3588\n",
      "Epoch 344/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2596 - mae: 0.3318 - val_loss: 0.3378 - val_mae: 0.3471\n",
      "Epoch 345/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2780 - mae: 0.3368 - val_loss: 0.3455 - val_mae: 0.3519\n",
      "Epoch 346/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2885 - mae: 0.3421 - val_loss: 0.3810 - val_mae: 0.3639\n",
      "Epoch 347/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2815 - mae: 0.3365 - val_loss: 0.4233 - val_mae: 0.3795\n",
      "Epoch 348/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2696 - mae: 0.3337 - val_loss: 0.4192 - val_mae: 0.3793\n",
      "Epoch 349/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2933 - mae: 0.3537 - val_loss: 0.3933 - val_mae: 0.3727\n",
      "Epoch 350/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2754 - mae: 0.3364 - val_loss: 0.3638 - val_mae: 0.3602\n",
      "Epoch 351/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2727 - mae: 0.3282 - val_loss: 0.3598 - val_mae: 0.3516\n",
      "Epoch 352/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2894 - mae: 0.3475 - val_loss: 0.3726 - val_mae: 0.3551\n",
      "Epoch 353/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3136 - mae: 0.3602 - val_loss: 0.3864 - val_mae: 0.3607\n",
      "Epoch 354/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2989 - mae: 0.3467 - val_loss: 0.3918 - val_mae: 0.3636\n",
      "Epoch 355/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2682 - mae: 0.3481 - val_loss: 0.3879 - val_mae: 0.3585\n",
      "Epoch 356/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2844 - mae: 0.3501 - val_loss: 0.3871 - val_mae: 0.3574\n",
      "Epoch 357/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2636 - mae: 0.3348 - val_loss: 0.3775 - val_mae: 0.3533\n",
      "Epoch 358/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3096 - mae: 0.3508 - val_loss: 0.3870 - val_mae: 0.3561\n",
      "Epoch 359/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2766 - mae: 0.3296 - val_loss: 0.3954 - val_mae: 0.3642\n",
      "Epoch 360/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2724 - mae: 0.3364 - val_loss: 0.4156 - val_mae: 0.3763\n",
      "Epoch 361/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2806 - mae: 0.3332 - val_loss: 0.4218 - val_mae: 0.3770\n",
      "Epoch 362/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2745 - mae: 0.3367 - val_loss: 0.4052 - val_mae: 0.3647\n",
      "Epoch 363/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3032 - mae: 0.3436 - val_loss: 0.3848 - val_mae: 0.3551\n",
      "Epoch 364/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2903 - mae: 0.3340 - val_loss: 0.3669 - val_mae: 0.3492\n",
      "Epoch 365/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2785 - mae: 0.3315 - val_loss: 0.3508 - val_mae: 0.3487\n",
      "Epoch 366/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2836 - mae: 0.3476 - val_loss: 0.3672 - val_mae: 0.3521\n",
      "Epoch 367/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2880 - mae: 0.3406 - val_loss: 0.3924 - val_mae: 0.3553\n",
      "Epoch 368/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2687 - mae: 0.3273 - val_loss: 0.4175 - val_mae: 0.3612\n",
      "Epoch 369/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3076 - mae: 0.3580 - val_loss: 0.4290 - val_mae: 0.3688\n",
      "Epoch 370/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2673 - mae: 0.3340 - val_loss: 0.3994 - val_mae: 0.3634\n",
      "Epoch 371/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2537 - mae: 0.3324 - val_loss: 0.3887 - val_mae: 0.3604\n",
      "Epoch 372/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2713 - mae: 0.3242 - val_loss: 0.4278 - val_mae: 0.3725\n",
      "Epoch 373/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2574 - mae: 0.3225 - val_loss: 0.4457 - val_mae: 0.3782\n",
      "Epoch 374/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2658 - mae: 0.3225 - val_loss: 0.4494 - val_mae: 0.3814\n",
      "Epoch 375/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2736 - mae: 0.3344 - val_loss: 0.4383 - val_mae: 0.3765\n",
      "Epoch 376/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2811 - mae: 0.3414 - val_loss: 0.4268 - val_mae: 0.3708\n",
      "Epoch 377/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2845 - mae: 0.3501 - val_loss: 0.4299 - val_mae: 0.3681\n",
      "Epoch 378/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2842 - mae: 0.3409 - val_loss: 0.4326 - val_mae: 0.3687\n",
      "Epoch 379/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2555 - mae: 0.3232 - val_loss: 0.4184 - val_mae: 0.3647\n",
      "Epoch 380/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2644 - mae: 0.3295 - val_loss: 0.4028 - val_mae: 0.3647\n",
      "Epoch 381/2000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2721 - mae: 0.3371 - val_loss: 0.3992 - val_mae: 0.3581\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# # Define the model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.SimpleRNN(32, activation='relu', input_shape=(15, 7)),  # Input layer\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),  # Hidden layer\n",
    "#     tf.keras.layers.Dense(4 * 7, activation=None)  # Output layer to predict 16 timesteps, each with 20 features\n",
    "# ])\n",
    "# model.add(tf.keras.layers.Reshape((4, 7)))  # Reshape output to match (16, 20)\n",
    "\n",
    "# Define the LSTM model with dropout\n",
    "model = tf.keras.Sequential([\n",
    "    # Adding dropout and recurrent dropout to the LSTM layer\n",
    "    tf.keras.layers.LSTM(32, activation='relu', input_shape=(15, 8),\n",
    "                         dropout=0.2, recurrent_dropout=0.2),\n",
    "    # Adding L2 regularization to the Dense layer\n",
    "    tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    # Output layer to predict 8 timesteps, each with 20 features\n",
    "    tf.keras.layers.Dense(4 * 8, activation=None)\n",
    "])\n",
    "model.add(tf.keras.layers.Reshape((4, 8)))  # Reshape output to match (8, 20)\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='mae', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Define optimizer\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2000, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "Test MAE: 0.3533\n",
      "Test RMSE: 0.5826\n",
      "Test R-squared: 0.7885\n",
      "Test MAE for CO2: 0.3476\n",
      "Test RMSE for CO2: 0.5534\n",
      "Test R-squared for CO2: 0.8516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Flatten the predictions and actual values for metric calculations\n",
    "y_true_flat = y_test.reshape(-1)\n",
    "y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
    "test_r2 = r2_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Test MAE: {test_mae:.4f}')\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "print(f'Test R-squared: {test_r2:.4f}')\n",
    "\n",
    "\n",
    "# Extracting predictions for CO2 (assuming it's the first column in the output)\n",
    "y_pred_co2 = y_pred[:, :, 0]  # Adjust the index if CO2 is not the first column\n",
    "y_true_co2 = y_test[:, :, 0]\n",
    "\n",
    "# Flatten the CO2 predictions and actual values\n",
    "y_true_co2_flat = y_true_co2.reshape(-1)\n",
    "y_pred_co2_flat = y_pred_co2.reshape(-1)\n",
    "\n",
    "# Calculate metrics for CO2\n",
    "test_mae_co2 = mean_absolute_error(y_true_co2_flat, y_pred_co2_flat)\n",
    "test_rmse_co2 = np.sqrt(mean_squared_error(y_true_co2_flat, y_pred_co2_flat))\n",
    "test_r2_co2 = r2_score(y_true_co2_flat, y_pred_co2_flat)\n",
    "\n",
    "# Print the metrics for CO2\n",
    "print(f'Test MAE for CO2: {test_mae_co2:.4f}')\n",
    "print(f'Test RMSE for CO2: {test_rmse_co2:.4f}')\n",
    "print(f'Test R-squared for CO2: {test_r2_co2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calculate_r2_per_feature(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the R-squared score for each feature across all timesteps.\n",
    "    Args:\n",
    "    y_true (numpy.ndarray): True values of the test set.\n",
    "    y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with feature indices as keys and R-squared scores as values.\n",
    "    \"\"\"\n",
    "    r2_scores = {}\n",
    "    for feature_index in range(y_true.shape[2]):  # Assuming the last dimension represents features\n",
    "        y_true_feature = y_true[:, :, feature_index].reshape(-1)\n",
    "        y_pred_feature = y_pred[:, :, feature_index].reshape(-1)\n",
    "        r2_scores[feature_index] = r2_score(y_true_feature, y_pred_feature)\n",
    "    return r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared scores for each feature: {0: 0.8515683650644381, 1: 0.5631788443380488, 2: 0.7162414497855659, 3: 0.871291000110087, 4: 0.2144733748108757, 5: 0.899297523281595, 6: 0.9358648249023022, 7: 0.8985953025047244}\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test and y_pred are already defined and contain the test and predicted data respectively.\n",
    "r2_scores = calculate_r2_per_feature(y_test, y_pred)\n",
    "print(\"R-squared scores for each feature:\", r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract feature names if available or use generic names\n",
    "feature_names = ['Feature {}'.format(i) for i in range(y_test.shape[2])]  # Adjust or replace with actual names\n",
    "\n",
    "# Extract R2 values and sort by value\n",
    "r2_values = [r2_scores[i] for i in sorted(r2_scores)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, r2_values, color='blue')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('R-squared Score')\n",
    "plt.title('R-squared Score for Each Feature')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to make room for label rotation\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
