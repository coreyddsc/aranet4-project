{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Corey Dearing\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as datetime\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Chen, Number of windows: 12\n",
      "Label: Song, Number of windows: 13\n"
     ]
    }
   ],
   "source": [
    "# Load the .npz file\n",
    "loaded_data = np.load('../datasets/windows.npz', allow_pickle=True)\n",
    "\n",
    "# Convert the loaded data back to a dictionary of lists of NumPy arrays, excluding 'column_names'\n",
    "windows = {label: list(arrays) for label, arrays in loaded_data.items() if label != 'column_names'}\n",
    "\n",
    "\n",
    "for label, windows_list in windows.items():\n",
    "    print(f\"Label: {label}, Number of windows: {len(windows_list)}\")\n",
    "\n",
    "# Extract the column names\n",
    "column_names = loaded_data['column_names']\n",
    "\n",
    "# Convert the loaded data back to a dictionary of lists of DataFrames, using the column names\n",
    "windows_df = {label: [pd.DataFrame(array, columns=column_names) for array in arrays_list] \n",
    "              for label, arrays_list in loaded_data.items() if label != 'column_names'}\n",
    "\n",
    "# Loop through windows_df and set 'Datetime' as the index\n",
    "for label, windows_list in windows_df.items():\n",
    "    for i, window in enumerate(windows_list):\n",
    "        # Convert 'Datetime' to a datetime object\n",
    "        window['Datetime'] = pd.to_datetime(window['Datetime'])\n",
    "\n",
    "        # Set 'Datetime' as the index\n",
    "        windows_df[label][i] = window.set_index('Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Chen\n",
      "Window 0: (76, 10)\n",
      "Window 1: (76, 10)\n",
      "Window 2: (76, 10)\n",
      "Window 3: (76, 10)\n",
      "Window 4: (76, 10)\n",
      "Window 5: (76, 10)\n",
      "Window 6: (76, 10)\n",
      "Window 7: (76, 10)\n",
      "Window 8: (76, 10)\n",
      "Window 9: (76, 10)\n",
      "Window 10: (76, 10)\n",
      "Window 11: (76, 10)\n",
      "Label: Song\n",
      "Window 0: (76, 10)\n",
      "Window 1: (76, 10)\n",
      "Window 2: (76, 10)\n",
      "Window 3: (76, 10)\n",
      "Window 4: (76, 10)\n",
      "Window 5: (76, 10)\n",
      "Window 6: (76, 10)\n",
      "Window 7: (76, 10)\n",
      "Window 8: (76, 10)\n",
      "Window 9: (76, 10)\n",
      "Window 10: (76, 10)\n",
      "Window 11: (76, 10)\n",
      "Window 12: (76, 10)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of each DataFrame in the windows dictionary\n",
    "for label, windows_list in windows.items():\n",
    "    print(f\"Label: {label}\")\n",
    "    for i, window in enumerate(windows_list):\n",
    "        print(f\"Window {i}: {window.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "      <th>tempF</th>\n",
       "      <th>rhumid</th>\n",
       "      <th>atmpr</th>\n",
       "      <th>door1</th>\n",
       "      <th>door2</th>\n",
       "      <th>hvac</th>\n",
       "      <th>subject_count</th>\n",
       "      <th>lecturer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:15:00</th>\n",
       "      <td>773.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:16:00</th>\n",
       "      <td>770.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:17:00</th>\n",
       "      <td>786.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:18:00</th>\n",
       "      <td>798.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14 12:19:00</th>\n",
       "      <td>824.0</td>\n",
       "      <td>74.1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1018.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       co2 tempF rhumid   atmpr door1 door2 hvac  \\\n",
       "Datetime                                                           \n",
       "2024-03-14 12:15:00  773.0  74.5   37.0  1018.1     1     1    0   \n",
       "2024-03-14 12:16:00  770.0  74.4   37.0  1018.1     1     1    0   \n",
       "2024-03-14 12:17:00  786.0  74.4   36.0  1018.1     1     1    0   \n",
       "2024-03-14 12:18:00  798.0  74.2   36.0  1018.0     1     1    0   \n",
       "2024-03-14 12:19:00  824.0  74.1   36.0  1018.1     1     1    0   \n",
       "\n",
       "                    subject_count lecturer  \n",
       "Datetime                                    \n",
       "2024-03-14 12:15:00           3.0        1  \n",
       "2024-03-14 12:16:00           3.0        1  \n",
       "2024-03-14 12:17:00           3.0        1  \n",
       "2024-03-14 12:18:00           3.0        1  \n",
       "2024-03-14 12:19:00           3.0        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_df['Song'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[Timestamp('2024-03-14 12:15:00'), 773.0, 74.5, 37.0, 1018.1, 1,\n",
       "        1, 0, 3.0, 1],\n",
       "       [Timestamp('2024-03-14 12:16:00'), 770.0, 74.4, 37.0, 1018.1, 1,\n",
       "        1, 0, 3.0, 1],\n",
       "       [Timestamp('2024-03-14 12:17:00'), 786.0, 74.4, 36.0, 1018.1, 1,\n",
       "        1, 0, 3.0, 1],\n",
       "       [Timestamp('2024-03-14 12:18:00'), 798.0, 74.2, 36.0, 1018.0, 1,\n",
       "        1, 0, 3.0, 1],\n",
       "       [Timestamp('2024-03-14 12:19:00'), 824.0, 74.1, 36.0, 1018.1, 1,\n",
       "        1, 0, 3.0, 1]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows['Song'][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (25, 76, 10)\n",
      "Shape of y: (25,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the 3D arrays and labels\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for label, windows_list in windows.items():\n",
    "    for window in windows_list:\n",
    "        # Convert each DataFrame to a NumPy array and append to the list\n",
    "        X_list.append(window)\n",
    "        # Append the corresponding label to the label list\n",
    "        y_list.append(label)\n",
    "\n",
    "# Convert the list of 3D arrays to a single 3D array (tensor)\n",
    "X = np.array(X_list)\n",
    "\n",
    "# Convert the label list to a NumPy array\n",
    "y = np.array(y_list)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `y` is our classifer, in this case it classifies lectures in `X` as `0` for `Song` or `1` for `Chen`. So if we take $n$ slices from each lecture intervals in each lecture $X_i \\in X$ to subsets $S_j \\in S$ such that $U_{j=0}^{n} S_j = X_i$, we will have to ensure labels from `y` are assigned accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisors of 76: [1, 2, 4, 19, 38, 76]\n"
     ]
    }
   ],
   "source": [
    "def find_divisors(n):\n",
    "    divisors = [i for i in range(1, n + 1) if n % i == 0]\n",
    "    return divisors\n",
    "\n",
    "# Find divisors of 76\n",
    "divisors_of_76 = find_divisors(76)\n",
    "print(\"Divisors of 76:\", divisors_of_76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of T: (100, 19, 10)\n",
      "New shape of y: (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your original array with shape (25, 76, 10)\n",
    "T = X.copy()\n",
    "\n",
    "# Verify that the second dimension is divisible by 2\n",
    "if T.shape[1] % 4 != 0:\n",
    "    raise ValueError(\"The number of records in each layer must be divisible by 2\")\n",
    "\n",
    "# Reshape T directly to the new shape\n",
    "# We reshape to (total number of new layers, new number of records per layer, number of features)\n",
    "# Total number of new layers = original layers * 2 because we split each layer into 2\n",
    "# New number of records per layer = original number of records per layer / 2\n",
    "new_layers = T.shape[0] * 4\n",
    "new_records_per_layer = T.shape[1] // 4\n",
    "T = T.reshape(new_layers, new_records_per_layer, T.shape[2])\n",
    "\n",
    "# Duplicate each element in y to match the new layer count\n",
    "y = np.repeat(y, 4)\n",
    "\n",
    "print(\"New shape of T:\", T.shape)\n",
    "print(\"New shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first and the last columns from the 3D array X\n",
    "T = T[:, :, 1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 19, 7)\n",
      "y_train shape: (80,)\n",
      "X_test shape: (20, 19, 7)\n",
      "y_test shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "T = T.astype(np.float64)\n",
    "# Encode labels: 'Song' as 1, 'Chen' as 0\n",
    "y = np.array([1 if label == 'Song' else 0 for label in y])\n",
    "# Scale the features using StandardScaler\n",
    "\n",
    "# Reshape X to 2D array\n",
    "T_2d = T.reshape(-1, T.shape[-1])\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "T_scaled = scaler.fit_transform(T_2d)\n",
    "\n",
    "# Reshape X_scaled back to 3D array\n",
    "T_scaled_3d = T_scaled.reshape(T.shape[0], T.shape[1], T.shape[2])\n",
    "\n",
    "# Split into training and test/validation sets\n",
    "T_train, T_test, y_train, y_test = train_test_split(T_scaled_3d, y, test_size=20, random_state=42, stratify=y)\n",
    "\n",
    "print(\"X_train shape:\", T_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", T_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Corey Dearing\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[19,7]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Corey Dearing\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From C:\\Users\\Corey Dearing\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Corey Dearing\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.6651 - accuracy: 0.0125 - val_loss: 3.1935 - val_accuracy: 0.1500\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.2900 - accuracy: 0.0750 - val_loss: 2.8310 - val_accuracy: 0.3000\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.9314 - accuracy: 0.1875 - val_loss: 2.5039 - val_accuracy: 0.4000\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.5892 - accuracy: 0.3375 - val_loss: 2.2105 - val_accuracy: 0.4500\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2726 - accuracy: 0.4625 - val_loss: 1.9507 - val_accuracy: 0.5000\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9752 - accuracy: 0.6500 - val_loss: 1.7250 - val_accuracy: 0.7000\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7244 - accuracy: 0.7250 - val_loss: 1.5302 - val_accuracy: 0.7000\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.5040 - accuracy: 0.8000 - val_loss: 1.3643 - val_accuracy: 0.7000\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.3138 - accuracy: 0.8500 - val_loss: 1.2193 - val_accuracy: 0.7500\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1525 - accuracy: 0.8750 - val_loss: 1.0965 - val_accuracy: 0.8500\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0169 - accuracy: 0.9375 - val_loss: 0.9911 - val_accuracy: 0.9500\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9063 - accuracy: 0.9375 - val_loss: 0.8991 - val_accuracy: 0.9500\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8094 - accuracy: 0.9375 - val_loss: 0.8217 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7245 - accuracy: 0.9500 - val_loss: 0.7572 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6589 - accuracy: 0.9500 - val_loss: 0.7015 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5987 - accuracy: 0.9500 - val_loss: 0.6511 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5476 - accuracy: 0.9500 - val_loss: 0.6053 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5027 - accuracy: 0.9625 - val_loss: 0.5660 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4632 - accuracy: 0.9625 - val_loss: 0.5332 - val_accuracy: 0.9500\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4290 - accuracy: 0.9625 - val_loss: 0.4953 - val_accuracy: 0.9500\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3977 - accuracy: 0.9625 - val_loss: 0.4660 - val_accuracy: 0.9500\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.9625 - val_loss: 0.4382 - val_accuracy: 0.9500\n",
      "Epoch 23/25\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3480 - accuracy: 0.9625 - val_loss: 0.4121 - val_accuracy: 0.9500\n",
      "Epoch 24/25\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3268 - accuracy: 0.9625 - val_loss: 0.3925 - val_accuracy: 0.9500\n",
      "Epoch 25/25\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3080 - accuracy: 0.9625 - val_loss: 0.3747 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(T_train, y_train, epochs=25, validation_data=(T_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 50], ylim=[0, 2], xlabel='Epochs', grid=True,\n",
    "    style=['r', 'r--', 'b', 'b-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3747 - accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3746911585330963, 0.949999988079071]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(T_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
       "       dtype=int64),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = model.predict(T_test)\n",
    "y_proba.round(2)\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9500\n",
      "Precision: 0.9545\n",
      "Recall: 0.9500\n",
      "F1-score: 0.9499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, average='macro'):\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Return metrics as a dictionary\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1}\n",
    "\n",
    "# Example usage (ensure y_test and y_pred are defined appropriately)\n",
    "metrics = evaluate_classification(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing RNN Sequenceing for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our sequenced samples M: (25, 76, 10)\n",
      "M_train shape: (20, 76, 10)\n",
      "M_test shape: (5, 76, 10)\n"
     ]
    }
   ],
   "source": [
    "M = X.copy()\n",
    "print(\"Shape of our sequenced samples M:\", M.shape)\n",
    "\n",
    "# Assuming M is already defined and has shape (25, 76, 20)\n",
    "# Set the seed for reproducibility and split the data\n",
    "M_train, M_test = train_test_split(M, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes to confirm the setup\n",
    "print(\"M_train shape:\", M_train.shape)  # Expected to have around 80% of the data\n",
    "print(\"M_test shape:\", M_test.shape)    # Expected to have around 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 15, 7)\n",
      "y_train shape: (80, 4, 7)\n",
      "X_test shape: (20, 15, 7)\n",
      "y_test shape: (20, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "# Calculating the split index for 90% of the time steps\n",
    "split_index = int(0.8 * 19)  \n",
    "\n",
    "# Splitting the training data\n",
    "X_train = T_train[:, :split_index, :]\n",
    "y_train = T_train[:, split_index:, :]\n",
    "\n",
    "# Splitting the testing data\n",
    "X_test = T_test[:, :split_index, :]\n",
    "y_test = T_test[:, split_index:, :]\n",
    "\n",
    "# Print shapes to confirm the setup\n",
    "print(\"X_train shape:\", X_train.shape)  \n",
    "print(\"y_train shape:\", y_train.shape)  \n",
    "print(\"X_test shape:\", X_test.shape)    \n",
    "print(\"y_test shape:\", y_test.shape)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 15, 7)\n",
      "y_train shape: (80, 4, 7)\n",
      "X_test shape: (20, 15, 7)\n",
      "y_test shape: (20, 4, 7)\n",
      "Epoch 1/2000\n",
      "3/3 [==============================] - 2s 116ms/step - loss: 1.1488 - mae: 0.8111 - val_loss: 1.5027 - val_mae: 0.9058\n",
      "Epoch 2/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1474 - mae: 0.8101 - val_loss: 1.4997 - val_mae: 0.9049\n",
      "Epoch 3/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1424 - mae: 0.8077 - val_loss: 1.4957 - val_mae: 0.9036\n",
      "Epoch 4/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.1346 - mae: 0.8053 - val_loss: 1.4910 - val_mae: 0.9020\n",
      "Epoch 5/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1264 - mae: 0.8013 - val_loss: 1.4860 - val_mae: 0.9003\n",
      "Epoch 6/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1205 - mae: 0.8000 - val_loss: 1.4809 - val_mae: 0.8986\n",
      "Epoch 7/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1089 - mae: 0.7946 - val_loss: 1.4754 - val_mae: 0.8967\n",
      "Epoch 8/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1035 - mae: 0.7929 - val_loss: 1.4700 - val_mae: 0.8949\n",
      "Epoch 9/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0940 - mae: 0.7883 - val_loss: 1.4644 - val_mae: 0.8930\n",
      "Epoch 10/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0870 - mae: 0.7858 - val_loss: 1.4586 - val_mae: 0.8910\n",
      "Epoch 11/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0762 - mae: 0.7814 - val_loss: 1.4527 - val_mae: 0.8889\n",
      "Epoch 12/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0699 - mae: 0.7790 - val_loss: 1.4463 - val_mae: 0.8866\n",
      "Epoch 13/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0636 - mae: 0.7759 - val_loss: 1.4398 - val_mae: 0.8844\n",
      "Epoch 14/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0508 - mae: 0.7709 - val_loss: 1.4332 - val_mae: 0.8821\n",
      "Epoch 15/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0437 - mae: 0.7675 - val_loss: 1.4261 - val_mae: 0.8796\n",
      "Epoch 16/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0365 - mae: 0.7636 - val_loss: 1.4194 - val_mae: 0.8774\n",
      "Epoch 17/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0253 - mae: 0.7597 - val_loss: 1.4124 - val_mae: 0.8749\n",
      "Epoch 18/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0178 - mae: 0.7567 - val_loss: 1.4048 - val_mae: 0.8721\n",
      "Epoch 19/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0063 - mae: 0.7520 - val_loss: 1.3970 - val_mae: 0.8690\n",
      "Epoch 20/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9979 - mae: 0.7463 - val_loss: 1.3894 - val_mae: 0.8658\n",
      "Epoch 21/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9919 - mae: 0.7418 - val_loss: 1.3821 - val_mae: 0.8627\n",
      "Epoch 22/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9832 - mae: 0.7390 - val_loss: 1.3752 - val_mae: 0.8599\n",
      "Epoch 23/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9742 - mae: 0.7347 - val_loss: 1.3683 - val_mae: 0.8571\n",
      "Epoch 24/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9681 - mae: 0.7310 - val_loss: 1.3618 - val_mae: 0.8546\n",
      "Epoch 25/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9582 - mae: 0.7265 - val_loss: 1.3547 - val_mae: 0.8519\n",
      "Epoch 26/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9524 - mae: 0.7247 - val_loss: 1.3475 - val_mae: 0.8492\n",
      "Epoch 27/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9441 - mae: 0.7189 - val_loss: 1.3404 - val_mae: 0.8466\n",
      "Epoch 28/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9379 - mae: 0.7178 - val_loss: 1.3325 - val_mae: 0.8434\n",
      "Epoch 29/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9277 - mae: 0.7104 - val_loss: 1.3241 - val_mae: 0.8400\n",
      "Epoch 30/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9211 - mae: 0.7056 - val_loss: 1.3158 - val_mae: 0.8364\n",
      "Epoch 31/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9143 - mae: 0.7016 - val_loss: 1.3066 - val_mae: 0.8330\n",
      "Epoch 32/2000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9058 - mae: 0.6986 - val_loss: 1.2974 - val_mae: 0.8297\n",
      "Epoch 33/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8998 - mae: 0.6952 - val_loss: 1.2880 - val_mae: 0.8263\n",
      "Epoch 34/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8941 - mae: 0.6922 - val_loss: 1.2787 - val_mae: 0.8233\n",
      "Epoch 35/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8868 - mae: 0.6886 - val_loss: 1.2692 - val_mae: 0.8205\n",
      "Epoch 36/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8741 - mae: 0.6830 - val_loss: 1.2600 - val_mae: 0.8179\n",
      "Epoch 37/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8735 - mae: 0.6838 - val_loss: 1.2509 - val_mae: 0.8154\n",
      "Epoch 38/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8725 - mae: 0.6833 - val_loss: 1.2430 - val_mae: 0.8128\n",
      "Epoch 39/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8641 - mae: 0.6772 - val_loss: 1.2348 - val_mae: 0.8098\n",
      "Epoch 40/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8576 - mae: 0.6781 - val_loss: 1.2256 - val_mae: 0.8064\n",
      "Epoch 41/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8549 - mae: 0.6734 - val_loss: 1.2169 - val_mae: 0.8034\n",
      "Epoch 42/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8434 - mae: 0.6693 - val_loss: 1.2086 - val_mae: 0.8005\n",
      "Epoch 43/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8376 - mae: 0.6645 - val_loss: 1.2016 - val_mae: 0.7981\n",
      "Epoch 44/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8360 - mae: 0.6630 - val_loss: 1.1941 - val_mae: 0.7954\n",
      "Epoch 45/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8272 - mae: 0.6601 - val_loss: 1.1847 - val_mae: 0.7918\n",
      "Epoch 46/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8236 - mae: 0.6567 - val_loss: 1.1745 - val_mae: 0.7880\n",
      "Epoch 47/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8176 - mae: 0.6543 - val_loss: 1.1652 - val_mae: 0.7843\n",
      "Epoch 48/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8123 - mae: 0.6499 - val_loss: 1.1555 - val_mae: 0.7805\n",
      "Epoch 49/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8090 - mae: 0.6481 - val_loss: 1.1467 - val_mae: 0.7771\n",
      "Epoch 50/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8003 - mae: 0.6446 - val_loss: 1.1381 - val_mae: 0.7740\n",
      "Epoch 51/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7981 - mae: 0.6430 - val_loss: 1.1286 - val_mae: 0.7702\n",
      "Epoch 52/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8015 - mae: 0.6429 - val_loss: 1.1234 - val_mae: 0.7683\n",
      "Epoch 53/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7895 - mae: 0.6404 - val_loss: 1.1183 - val_mae: 0.7665\n",
      "Epoch 54/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7858 - mae: 0.6417 - val_loss: 1.1106 - val_mae: 0.7631\n",
      "Epoch 55/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7771 - mae: 0.6366 - val_loss: 1.1003 - val_mae: 0.7583\n",
      "Epoch 56/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7721 - mae: 0.6300 - val_loss: 1.0893 - val_mae: 0.7534\n",
      "Epoch 57/2000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7654 - mae: 0.6289 - val_loss: 1.0799 - val_mae: 0.7491\n",
      "Epoch 58/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7648 - mae: 0.6307 - val_loss: 1.0728 - val_mae: 0.7459\n",
      "Epoch 59/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7577 - mae: 0.6235 - val_loss: 1.0640 - val_mae: 0.7418\n",
      "Epoch 60/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7551 - mae: 0.6227 - val_loss: 1.0568 - val_mae: 0.7380\n",
      "Epoch 61/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7495 - mae: 0.6233 - val_loss: 1.0468 - val_mae: 0.7330\n",
      "Epoch 62/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7413 - mae: 0.6137 - val_loss: 1.0373 - val_mae: 0.7280\n",
      "Epoch 63/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7356 - mae: 0.6115 - val_loss: 1.0286 - val_mae: 0.7237\n",
      "Epoch 64/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7327 - mae: 0.6122 - val_loss: 1.0222 - val_mae: 0.7202\n",
      "Epoch 65/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7287 - mae: 0.6079 - val_loss: 1.0140 - val_mae: 0.7160\n",
      "Epoch 66/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7312 - mae: 0.6107 - val_loss: 1.0097 - val_mae: 0.7147\n",
      "Epoch 67/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7130 - mae: 0.6026 - val_loss: 1.0104 - val_mae: 0.7159\n",
      "Epoch 68/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7179 - mae: 0.6068 - val_loss: 1.0043 - val_mae: 0.7133\n",
      "Epoch 69/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7073 - mae: 0.6029 - val_loss: 0.9918 - val_mae: 0.7076\n",
      "Epoch 70/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7024 - mae: 0.5973 - val_loss: 0.9790 - val_mae: 0.7015\n",
      "Epoch 71/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6963 - mae: 0.5956 - val_loss: 0.9646 - val_mae: 0.6942\n",
      "Epoch 72/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6901 - mae: 0.5873 - val_loss: 0.9502 - val_mae: 0.6875\n",
      "Epoch 73/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6854 - mae: 0.5866 - val_loss: 0.9378 - val_mae: 0.6812\n",
      "Epoch 74/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6757 - mae: 0.5790 - val_loss: 0.9263 - val_mae: 0.6755\n",
      "Epoch 75/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6840 - mae: 0.5846 - val_loss: 0.9197 - val_mae: 0.6731\n",
      "Epoch 76/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6652 - mae: 0.5771 - val_loss: 0.9140 - val_mae: 0.6721\n",
      "Epoch 77/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6527 - mae: 0.5744 - val_loss: 0.9088 - val_mae: 0.6714\n",
      "Epoch 78/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6515 - mae: 0.5739 - val_loss: 0.8999 - val_mae: 0.6682\n",
      "Epoch 79/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6523 - mae: 0.5748 - val_loss: 0.8897 - val_mae: 0.6638\n",
      "Epoch 80/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6424 - mae: 0.5699 - val_loss: 0.8798 - val_mae: 0.6589\n",
      "Epoch 81/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6403 - mae: 0.5646 - val_loss: 0.8675 - val_mae: 0.6532\n",
      "Epoch 82/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6317 - mae: 0.5622 - val_loss: 0.8534 - val_mae: 0.6472\n",
      "Epoch 83/2000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6245 - mae: 0.5607 - val_loss: 0.8411 - val_mae: 0.6423\n",
      "Epoch 84/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6101 - mae: 0.5478 - val_loss: 0.8298 - val_mae: 0.6370\n",
      "Epoch 85/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6092 - mae: 0.5496 - val_loss: 0.8187 - val_mae: 0.6321\n",
      "Epoch 86/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6073 - mae: 0.5431 - val_loss: 0.8105 - val_mae: 0.6277\n",
      "Epoch 87/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5938 - mae: 0.5385 - val_loss: 0.8022 - val_mae: 0.6242\n",
      "Epoch 88/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5891 - mae: 0.5344 - val_loss: 0.7949 - val_mae: 0.6218\n",
      "Epoch 89/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5833 - mae: 0.5311 - val_loss: 0.7878 - val_mae: 0.6193\n",
      "Epoch 90/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5765 - mae: 0.5332 - val_loss: 0.7765 - val_mae: 0.6146\n",
      "Epoch 91/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5726 - mae: 0.5279 - val_loss: 0.7648 - val_mae: 0.6093\n",
      "Epoch 92/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5703 - mae: 0.5297 - val_loss: 0.7614 - val_mae: 0.6065\n",
      "Epoch 93/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5570 - mae: 0.5228 - val_loss: 0.7573 - val_mae: 0.6046\n",
      "Epoch 94/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5545 - mae: 0.5212 - val_loss: 0.7497 - val_mae: 0.6006\n",
      "Epoch 95/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5509 - mae: 0.5182 - val_loss: 0.7385 - val_mae: 0.5956\n",
      "Epoch 96/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5442 - mae: 0.5103 - val_loss: 0.7250 - val_mae: 0.5892\n",
      "Epoch 97/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5526 - mae: 0.5200 - val_loss: 0.7214 - val_mae: 0.5860\n",
      "Epoch 98/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5351 - mae: 0.5058 - val_loss: 0.7213 - val_mae: 0.5849\n",
      "Epoch 99/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5294 - mae: 0.5074 - val_loss: 0.7178 - val_mae: 0.5822\n",
      "Epoch 100/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5313 - mae: 0.5041 - val_loss: 0.7039 - val_mae: 0.5750\n",
      "Epoch 101/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5239 - mae: 0.4988 - val_loss: 0.6926 - val_mae: 0.5694\n",
      "Epoch 102/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5140 - mae: 0.4920 - val_loss: 0.6837 - val_mae: 0.5641\n",
      "Epoch 103/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5147 - mae: 0.4902 - val_loss: 0.6761 - val_mae: 0.5596\n",
      "Epoch 104/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5047 - mae: 0.4872 - val_loss: 0.6678 - val_mae: 0.5570\n",
      "Epoch 105/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4947 - mae: 0.4814 - val_loss: 0.6736 - val_mae: 0.5611\n",
      "Epoch 106/2000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5000 - mae: 0.4863 - val_loss: 0.6742 - val_mae: 0.5622\n",
      "Epoch 107/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4992 - mae: 0.4829 - val_loss: 0.6675 - val_mae: 0.5591\n",
      "Epoch 108/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4816 - mae: 0.4778 - val_loss: 0.6577 - val_mae: 0.5521\n",
      "Epoch 109/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4848 - mae: 0.4777 - val_loss: 0.6544 - val_mae: 0.5475\n",
      "Epoch 110/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4760 - mae: 0.4771 - val_loss: 0.6463 - val_mae: 0.5397\n",
      "Epoch 111/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4780 - mae: 0.4682 - val_loss: 0.6323 - val_mae: 0.5299\n",
      "Epoch 112/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4754 - mae: 0.4626 - val_loss: 0.6238 - val_mae: 0.5232\n",
      "Epoch 113/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4587 - mae: 0.4545 - val_loss: 0.6242 - val_mae: 0.5246\n",
      "Epoch 114/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4617 - mae: 0.4589 - val_loss: 0.6224 - val_mae: 0.5252\n",
      "Epoch 115/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4480 - mae: 0.4494 - val_loss: 0.6110 - val_mae: 0.5217\n",
      "Epoch 116/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4579 - mae: 0.4559 - val_loss: 0.6053 - val_mae: 0.5201\n",
      "Epoch 117/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4480 - mae: 0.4506 - val_loss: 0.6070 - val_mae: 0.5217\n",
      "Epoch 118/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4482 - mae: 0.4485 - val_loss: 0.6114 - val_mae: 0.5216\n",
      "Epoch 119/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4451 - mae: 0.4448 - val_loss: 0.5981 - val_mae: 0.5159\n",
      "Epoch 120/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4461 - mae: 0.4457 - val_loss: 0.5901 - val_mae: 0.5112\n",
      "Epoch 121/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4405 - mae: 0.4455 - val_loss: 0.5942 - val_mae: 0.5169\n",
      "Epoch 122/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4334 - mae: 0.4485 - val_loss: 0.6009 - val_mae: 0.5232\n",
      "Epoch 123/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4289 - mae: 0.4483 - val_loss: 0.5884 - val_mae: 0.5146\n",
      "Epoch 124/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4325 - mae: 0.4427 - val_loss: 0.5805 - val_mae: 0.5067\n",
      "Epoch 125/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4298 - mae: 0.4389 - val_loss: 0.5848 - val_mae: 0.5036\n",
      "Epoch 126/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4159 - mae: 0.4323 - val_loss: 0.5851 - val_mae: 0.4997\n",
      "Epoch 127/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4146 - mae: 0.4268 - val_loss: 0.5765 - val_mae: 0.4922\n",
      "Epoch 128/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4247 - mae: 0.4333 - val_loss: 0.5665 - val_mae: 0.4907\n",
      "Epoch 129/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4247 - mae: 0.4297 - val_loss: 0.5690 - val_mae: 0.4910\n",
      "Epoch 130/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4080 - mae: 0.4284 - val_loss: 0.5630 - val_mae: 0.4890\n",
      "Epoch 131/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4039 - mae: 0.4225 - val_loss: 0.5520 - val_mae: 0.4842\n",
      "Epoch 132/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3979 - mae: 0.4198 - val_loss: 0.5405 - val_mae: 0.4792\n",
      "Epoch 133/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3911 - mae: 0.4130 - val_loss: 0.5393 - val_mae: 0.4770\n",
      "Epoch 134/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4006 - mae: 0.4163 - val_loss: 0.5387 - val_mae: 0.4770\n",
      "Epoch 135/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3973 - mae: 0.4141 - val_loss: 0.5334 - val_mae: 0.4742\n",
      "Epoch 136/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3805 - mae: 0.4046 - val_loss: 0.5303 - val_mae: 0.4730\n",
      "Epoch 137/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3921 - mae: 0.4111 - val_loss: 0.5300 - val_mae: 0.4731\n",
      "Epoch 138/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3803 - mae: 0.4043 - val_loss: 0.5395 - val_mae: 0.4763\n",
      "Epoch 139/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3794 - mae: 0.4054 - val_loss: 0.5313 - val_mae: 0.4719\n",
      "Epoch 140/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3786 - mae: 0.4053 - val_loss: 0.5241 - val_mae: 0.4690\n",
      "Epoch 141/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3783 - mae: 0.4013 - val_loss: 0.5216 - val_mae: 0.4663\n",
      "Epoch 142/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3672 - mae: 0.3951 - val_loss: 0.5214 - val_mae: 0.4656\n",
      "Epoch 143/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3754 - mae: 0.3992 - val_loss: 0.5263 - val_mae: 0.4656\n",
      "Epoch 144/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3699 - mae: 0.3961 - val_loss: 0.5218 - val_mae: 0.4620\n",
      "Epoch 145/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3572 - mae: 0.3851 - val_loss: 0.5233 - val_mae: 0.4623\n",
      "Epoch 146/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3576 - mae: 0.3864 - val_loss: 0.5305 - val_mae: 0.4638\n",
      "Epoch 147/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3651 - mae: 0.3882 - val_loss: 0.5306 - val_mae: 0.4635\n",
      "Epoch 148/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3594 - mae: 0.3840 - val_loss: 0.5215 - val_mae: 0.4594\n",
      "Epoch 149/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3541 - mae: 0.3812 - val_loss: 0.5090 - val_mae: 0.4545\n",
      "Epoch 150/2000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3543 - mae: 0.3889 - val_loss: 0.5056 - val_mae: 0.4540\n",
      "Epoch 151/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3541 - mae: 0.3895 - val_loss: 0.4991 - val_mae: 0.4535\n",
      "Epoch 152/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3606 - mae: 0.3917 - val_loss: 0.4972 - val_mae: 0.4503\n",
      "Epoch 153/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3469 - mae: 0.3820 - val_loss: 0.4992 - val_mae: 0.4497\n",
      "Epoch 154/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3404 - mae: 0.3793 - val_loss: 0.4972 - val_mae: 0.4496\n",
      "Epoch 155/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3365 - mae: 0.3758 - val_loss: 0.4993 - val_mae: 0.4518\n",
      "Epoch 156/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3375 - mae: 0.3746 - val_loss: 0.5008 - val_mae: 0.4522\n",
      "Epoch 157/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3408 - mae: 0.3789 - val_loss: 0.5034 - val_mae: 0.4491\n",
      "Epoch 158/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3319 - mae: 0.3695 - val_loss: 0.5094 - val_mae: 0.4470\n",
      "Epoch 159/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3407 - mae: 0.3762 - val_loss: 0.4982 - val_mae: 0.4459\n",
      "Epoch 160/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3366 - mae: 0.3720 - val_loss: 0.4933 - val_mae: 0.4477\n",
      "Epoch 161/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3298 - mae: 0.3729 - val_loss: 0.4934 - val_mae: 0.4495\n",
      "Epoch 162/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3388 - mae: 0.3755 - val_loss: 0.4887 - val_mae: 0.4428\n",
      "Epoch 163/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3296 - mae: 0.3703 - val_loss: 0.4841 - val_mae: 0.4434\n",
      "Epoch 164/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3230 - mae: 0.3658 - val_loss: 0.4798 - val_mae: 0.4409\n",
      "Epoch 165/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3293 - mae: 0.3778 - val_loss: 0.4824 - val_mae: 0.4440\n",
      "Epoch 166/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3281 - mae: 0.3722 - val_loss: 0.4941 - val_mae: 0.4500\n",
      "Epoch 167/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3220 - mae: 0.3634 - val_loss: 0.4981 - val_mae: 0.4501\n",
      "Epoch 168/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3221 - mae: 0.3626 - val_loss: 0.4931 - val_mae: 0.4410\n",
      "Epoch 169/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3275 - mae: 0.3686 - val_loss: 0.4885 - val_mae: 0.4387\n",
      "Epoch 170/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3229 - mae: 0.3659 - val_loss: 0.4897 - val_mae: 0.4416\n",
      "Epoch 171/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3232 - mae: 0.3701 - val_loss: 0.4856 - val_mae: 0.4400\n",
      "Epoch 172/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3176 - mae: 0.3636 - val_loss: 0.4784 - val_mae: 0.4362\n",
      "Epoch 173/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3240 - mae: 0.3638 - val_loss: 0.4781 - val_mae: 0.4363\n",
      "Epoch 174/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3140 - mae: 0.3665 - val_loss: 0.4784 - val_mae: 0.4337\n",
      "Epoch 175/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3097 - mae: 0.3591 - val_loss: 0.4931 - val_mae: 0.4384\n",
      "Epoch 176/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3176 - mae: 0.3550 - val_loss: 0.4905 - val_mae: 0.4359\n",
      "Epoch 177/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2996 - mae: 0.3472 - val_loss: 0.4821 - val_mae: 0.4354\n",
      "Epoch 178/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3102 - mae: 0.3544 - val_loss: 0.4735 - val_mae: 0.4361\n",
      "Epoch 179/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3063 - mae: 0.3565 - val_loss: 0.4646 - val_mae: 0.4305\n",
      "Epoch 180/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3061 - mae: 0.3585 - val_loss: 0.4567 - val_mae: 0.4238\n",
      "Epoch 181/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3125 - mae: 0.3596 - val_loss: 0.4575 - val_mae: 0.4223\n",
      "Epoch 182/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3081 - mae: 0.3561 - val_loss: 0.4603 - val_mae: 0.4222\n",
      "Epoch 183/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2941 - mae: 0.3441 - val_loss: 0.4557 - val_mae: 0.4225\n",
      "Epoch 184/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3030 - mae: 0.3525 - val_loss: 0.4553 - val_mae: 0.4202\n",
      "Epoch 185/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2979 - mae: 0.3439 - val_loss: 0.4554 - val_mae: 0.4197\n",
      "Epoch 186/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2883 - mae: 0.3450 - val_loss: 0.4604 - val_mae: 0.4242\n",
      "Epoch 187/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2934 - mae: 0.3464 - val_loss: 0.4693 - val_mae: 0.4313\n",
      "Epoch 188/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2984 - mae: 0.3507 - val_loss: 0.4693 - val_mae: 0.4268\n",
      "Epoch 189/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2877 - mae: 0.3402 - val_loss: 0.4580 - val_mae: 0.4192\n",
      "Epoch 190/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2857 - mae: 0.3413 - val_loss: 0.4496 - val_mae: 0.4155\n",
      "Epoch 191/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2941 - mae: 0.3468 - val_loss: 0.4593 - val_mae: 0.4288\n",
      "Epoch 192/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2977 - mae: 0.3569 - val_loss: 0.4754 - val_mae: 0.4399\n",
      "Epoch 193/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3031 - mae: 0.3588 - val_loss: 0.4706 - val_mae: 0.4279\n",
      "Epoch 194/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2914 - mae: 0.3457 - val_loss: 0.4662 - val_mae: 0.4254\n",
      "Epoch 195/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2940 - mae: 0.3479 - val_loss: 0.4624 - val_mae: 0.4215\n",
      "Epoch 196/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2799 - mae: 0.3404 - val_loss: 0.4752 - val_mae: 0.4344\n",
      "Epoch 197/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2943 - mae: 0.3523 - val_loss: 0.4630 - val_mae: 0.4280\n",
      "Epoch 198/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2858 - mae: 0.3423 - val_loss: 0.4408 - val_mae: 0.4140\n",
      "Epoch 199/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2926 - mae: 0.3446 - val_loss: 0.4291 - val_mae: 0.4063\n",
      "Epoch 200/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2791 - mae: 0.3349 - val_loss: 0.4285 - val_mae: 0.4066\n",
      "Epoch 201/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2812 - mae: 0.3399 - val_loss: 0.4372 - val_mae: 0.4074\n",
      "Epoch 202/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2942 - mae: 0.3491 - val_loss: 0.4508 - val_mae: 0.4143\n",
      "Epoch 203/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2681 - mae: 0.3278 - val_loss: 0.4492 - val_mae: 0.4143\n",
      "Epoch 204/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2773 - mae: 0.3343 - val_loss: 0.4510 - val_mae: 0.4178\n",
      "Epoch 205/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2755 - mae: 0.3349 - val_loss: 0.4505 - val_mae: 0.4159\n",
      "Epoch 206/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2782 - mae: 0.3394 - val_loss: 0.4435 - val_mae: 0.4112\n",
      "Epoch 207/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2710 - mae: 0.3261 - val_loss: 0.4364 - val_mae: 0.4061\n",
      "Epoch 208/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2694 - mae: 0.3292 - val_loss: 0.4354 - val_mae: 0.4079\n",
      "Epoch 209/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2612 - mae: 0.3218 - val_loss: 0.4286 - val_mae: 0.4014\n",
      "Epoch 210/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2717 - mae: 0.3346 - val_loss: 0.4234 - val_mae: 0.3981\n",
      "Epoch 211/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2709 - mae: 0.3306 - val_loss: 0.4226 - val_mae: 0.4008\n",
      "Epoch 212/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2739 - mae: 0.3343 - val_loss: 0.4303 - val_mae: 0.4112\n",
      "Epoch 213/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2643 - mae: 0.3253 - val_loss: 0.4358 - val_mae: 0.4121\n",
      "Epoch 214/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2678 - mae: 0.3342 - val_loss: 0.4274 - val_mae: 0.4031\n",
      "Epoch 215/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2651 - mae: 0.3291 - val_loss: 0.4238 - val_mae: 0.3984\n",
      "Epoch 216/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2740 - mae: 0.3363 - val_loss: 0.4289 - val_mae: 0.4053\n",
      "Epoch 217/2000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2625 - mae: 0.3240 - val_loss: 0.4347 - val_mae: 0.4138\n",
      "Epoch 218/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2603 - mae: 0.3216 - val_loss: 0.4238 - val_mae: 0.4072\n",
      "Epoch 219/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2625 - mae: 0.3248 - val_loss: 0.4140 - val_mae: 0.4000\n",
      "Epoch 220/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2582 - mae: 0.3239 - val_loss: 0.4205 - val_mae: 0.4011\n",
      "Epoch 221/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2639 - mae: 0.3262 - val_loss: 0.4264 - val_mae: 0.4022\n",
      "Epoch 222/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2582 - mae: 0.3221 - val_loss: 0.4281 - val_mae: 0.4033\n",
      "Epoch 223/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2492 - mae: 0.3146 - val_loss: 0.4219 - val_mae: 0.3993\n",
      "Epoch 224/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2490 - mae: 0.3182 - val_loss: 0.4189 - val_mae: 0.3988\n",
      "Epoch 225/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2670 - mae: 0.3280 - val_loss: 0.4152 - val_mae: 0.3941\n",
      "Epoch 226/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2597 - mae: 0.3245 - val_loss: 0.4266 - val_mae: 0.4018\n",
      "Epoch 227/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2543 - mae: 0.3180 - val_loss: 0.4335 - val_mae: 0.4054\n",
      "Epoch 228/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2655 - mae: 0.3260 - val_loss: 0.4187 - val_mae: 0.3957\n",
      "Epoch 229/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2615 - mae: 0.3225 - val_loss: 0.4103 - val_mae: 0.3930\n",
      "Epoch 230/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2576 - mae: 0.3211 - val_loss: 0.4262 - val_mae: 0.4037\n",
      "Epoch 231/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2590 - mae: 0.3202 - val_loss: 0.4384 - val_mae: 0.4065\n",
      "Epoch 232/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2561 - mae: 0.3172 - val_loss: 0.4320 - val_mae: 0.4002\n",
      "Epoch 233/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2451 - mae: 0.3158 - val_loss: 0.4262 - val_mae: 0.4016\n",
      "Epoch 234/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2605 - mae: 0.3340 - val_loss: 0.4255 - val_mae: 0.4032\n",
      "Epoch 235/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2631 - mae: 0.3333 - val_loss: 0.4191 - val_mae: 0.3948\n",
      "Epoch 236/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2530 - mae: 0.3183 - val_loss: 0.4159 - val_mae: 0.3973\n",
      "Epoch 237/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2498 - mae: 0.3182 - val_loss: 0.4117 - val_mae: 0.3955\n",
      "Epoch 238/2000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2470 - mae: 0.3177 - val_loss: 0.4072 - val_mae: 0.3908\n",
      "Epoch 239/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2459 - mae: 0.3162 - val_loss: 0.4030 - val_mae: 0.3917\n",
      "Epoch 240/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2572 - mae: 0.3227 - val_loss: 0.4033 - val_mae: 0.3958\n",
      "Epoch 241/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2442 - mae: 0.3182 - val_loss: 0.4008 - val_mae: 0.3946\n",
      "Epoch 242/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2416 - mae: 0.3105 - val_loss: 0.4045 - val_mae: 0.3903\n",
      "Epoch 243/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2418 - mae: 0.3088 - val_loss: 0.3956 - val_mae: 0.3814\n",
      "Epoch 244/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2438 - mae: 0.3162 - val_loss: 0.3945 - val_mae: 0.3823\n",
      "Epoch 245/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2451 - mae: 0.3154 - val_loss: 0.4128 - val_mae: 0.3924\n",
      "Epoch 246/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2396 - mae: 0.3143 - val_loss: 0.4189 - val_mae: 0.3945\n",
      "Epoch 247/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2589 - mae: 0.3197 - val_loss: 0.4214 - val_mae: 0.3919\n",
      "Epoch 248/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2454 - mae: 0.3105 - val_loss: 0.4220 - val_mae: 0.3923\n",
      "Epoch 249/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2485 - mae: 0.3227 - val_loss: 0.4046 - val_mae: 0.3869\n",
      "Epoch 250/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2435 - mae: 0.3125 - val_loss: 0.4147 - val_mae: 0.4036\n",
      "Epoch 251/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2494 - mae: 0.3204 - val_loss: 0.4137 - val_mae: 0.3962\n",
      "Epoch 252/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2358 - mae: 0.3075 - val_loss: 0.4083 - val_mae: 0.3893\n",
      "Epoch 253/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2422 - mae: 0.3124 - val_loss: 0.4007 - val_mae: 0.3835\n",
      "Epoch 254/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2476 - mae: 0.3185 - val_loss: 0.4052 - val_mae: 0.3945\n",
      "Epoch 255/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2441 - mae: 0.3164 - val_loss: 0.3982 - val_mae: 0.3911\n",
      "Epoch 256/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2317 - mae: 0.3043 - val_loss: 0.4037 - val_mae: 0.3854\n",
      "Epoch 257/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2233 - mae: 0.2981 - val_loss: 0.4157 - val_mae: 0.3873\n",
      "Epoch 258/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2280 - mae: 0.3040 - val_loss: 0.4108 - val_mae: 0.3904\n",
      "Epoch 259/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2457 - mae: 0.3186 - val_loss: 0.4000 - val_mae: 0.3881\n",
      "Epoch 260/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2291 - mae: 0.3065 - val_loss: 0.4094 - val_mae: 0.3893\n",
      "Epoch 261/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2300 - mae: 0.3019 - val_loss: 0.4165 - val_mae: 0.3924\n",
      "Epoch 262/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2388 - mae: 0.3065 - val_loss: 0.4088 - val_mae: 0.3950\n",
      "Epoch 263/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2350 - mae: 0.3074 - val_loss: 0.4019 - val_mae: 0.3939\n",
      "Epoch 264/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2362 - mae: 0.3062 - val_loss: 0.4086 - val_mae: 0.3875\n",
      "Epoch 265/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2288 - mae: 0.3014 - val_loss: 0.4086 - val_mae: 0.3820\n",
      "Epoch 266/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2320 - mae: 0.3047 - val_loss: 0.4044 - val_mae: 0.3854\n",
      "Epoch 267/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2430 - mae: 0.3160 - val_loss: 0.4080 - val_mae: 0.3994\n",
      "Epoch 268/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2279 - mae: 0.3112 - val_loss: 0.4123 - val_mae: 0.3922\n",
      "Epoch 269/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2224 - mae: 0.3015 - val_loss: 0.4109 - val_mae: 0.3859\n",
      "Epoch 270/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2261 - mae: 0.2963 - val_loss: 0.4051 - val_mae: 0.3867\n",
      "Epoch 271/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2368 - mae: 0.3026 - val_loss: 0.4064 - val_mae: 0.3957\n",
      "Epoch 272/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2165 - mae: 0.2959 - val_loss: 0.4012 - val_mae: 0.3897\n",
      "Epoch 273/2000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2236 - mae: 0.2944 - val_loss: 0.4064 - val_mae: 0.3886\n",
      "Epoch 274/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2183 - mae: 0.3013 - val_loss: 0.4207 - val_mae: 0.3991\n",
      "Epoch 275/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2250 - mae: 0.2991 - val_loss: 0.4291 - val_mae: 0.4100\n",
      "Epoch 276/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2151 - mae: 0.2954 - val_loss: 0.4260 - val_mae: 0.4064\n",
      "Epoch 277/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2131 - mae: 0.2938 - val_loss: 0.4154 - val_mae: 0.3905\n",
      "Epoch 278/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2223 - mae: 0.2946 - val_loss: 0.4098 - val_mae: 0.3804\n",
      "Epoch 279/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2288 - mae: 0.3043 - val_loss: 0.4044 - val_mae: 0.3857\n",
      "Epoch 280/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2160 - mae: 0.2964 - val_loss: 0.4093 - val_mae: 0.3979\n",
      "Epoch 281/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2276 - mae: 0.3056 - val_loss: 0.4026 - val_mae: 0.3910\n",
      "Epoch 282/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2140 - mae: 0.2889 - val_loss: 0.3947 - val_mae: 0.3864\n",
      "Epoch 283/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2182 - mae: 0.2904 - val_loss: 0.3980 - val_mae: 0.3860\n",
      "Epoch 284/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2183 - mae: 0.2913 - val_loss: 0.4149 - val_mae: 0.3967\n",
      "Epoch 285/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2239 - mae: 0.3015 - val_loss: 0.4180 - val_mae: 0.3950\n",
      "Epoch 286/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2210 - mae: 0.2968 - val_loss: 0.4234 - val_mae: 0.3957\n",
      "Epoch 287/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2089 - mae: 0.2888 - val_loss: 0.4172 - val_mae: 0.3910\n",
      "Epoch 288/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2209 - mae: 0.2974 - val_loss: 0.4041 - val_mae: 0.3850\n",
      "Epoch 289/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2210 - mae: 0.3057 - val_loss: 0.4075 - val_mae: 0.3956\n",
      "Epoch 290/2000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2079 - mae: 0.2886 - val_loss: 0.4026 - val_mae: 0.3929\n",
      "Epoch 291/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2115 - mae: 0.2910 - val_loss: 0.4072 - val_mae: 0.3873\n",
      "Epoch 292/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2188 - mae: 0.2903 - val_loss: 0.4163 - val_mae: 0.3885\n",
      "Epoch 293/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2109 - mae: 0.2898 - val_loss: 0.4149 - val_mae: 0.3924\n",
      "Epoch 294/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2118 - mae: 0.2909 - val_loss: 0.4031 - val_mae: 0.3899\n",
      "Epoch 295/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2185 - mae: 0.2999 - val_loss: 0.4013 - val_mae: 0.3882\n",
      "Epoch 296/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2199 - mae: 0.2913 - val_loss: 0.4036 - val_mae: 0.3869\n",
      "Epoch 297/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2116 - mae: 0.2947 - val_loss: 0.3938 - val_mae: 0.3863\n",
      "Epoch 298/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2137 - mae: 0.2860 - val_loss: 0.4121 - val_mae: 0.3992\n",
      "Epoch 299/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2116 - mae: 0.2873 - val_loss: 0.4303 - val_mae: 0.4031\n",
      "Epoch 300/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2029 - mae: 0.2836 - val_loss: 0.4132 - val_mae: 0.3923\n",
      "Epoch 301/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2160 - mae: 0.2898 - val_loss: 0.4049 - val_mae: 0.3903\n",
      "Epoch 302/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2065 - mae: 0.2920 - val_loss: 0.4124 - val_mae: 0.3920\n",
      "Epoch 303/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1962 - mae: 0.2808 - val_loss: 0.4320 - val_mae: 0.3992\n",
      "Epoch 304/2000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2050 - mae: 0.2779 - val_loss: 0.4219 - val_mae: 0.3946\n",
      "Epoch 305/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2034 - mae: 0.2843 - val_loss: 0.3988 - val_mae: 0.3795\n",
      "Epoch 306/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2162 - mae: 0.2982 - val_loss: 0.4071 - val_mae: 0.3812\n",
      "Epoch 307/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2112 - mae: 0.2981 - val_loss: 0.4374 - val_mae: 0.4048\n",
      "Epoch 308/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2083 - mae: 0.2882 - val_loss: 0.4565 - val_mae: 0.4205\n",
      "Epoch 309/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2075 - mae: 0.2849 - val_loss: 0.4354 - val_mae: 0.3987\n",
      "Epoch 310/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2061 - mae: 0.2872 - val_loss: 0.4297 - val_mae: 0.3899\n",
      "Epoch 311/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2023 - mae: 0.2828 - val_loss: 0.4294 - val_mae: 0.3901\n",
      "Epoch 312/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2007 - mae: 0.2859 - val_loss: 0.4206 - val_mae: 0.3922\n",
      "Epoch 313/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2127 - mae: 0.2882 - val_loss: 0.4261 - val_mae: 0.4020\n",
      "Epoch 314/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2015 - mae: 0.2846 - val_loss: 0.4415 - val_mae: 0.4033\n",
      "Epoch 315/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2171 - mae: 0.2903 - val_loss: 0.4438 - val_mae: 0.4025\n",
      "Epoch 316/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2038 - mae: 0.2894 - val_loss: 0.4315 - val_mae: 0.3965\n",
      "Epoch 317/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1978 - mae: 0.2827 - val_loss: 0.4317 - val_mae: 0.4005\n",
      "Epoch 318/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2016 - mae: 0.2831 - val_loss: 0.4373 - val_mae: 0.4019\n",
      "Epoch 319/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2075 - mae: 0.2821 - val_loss: 0.4466 - val_mae: 0.4039\n",
      "Epoch 320/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2145 - mae: 0.2891 - val_loss: 0.4218 - val_mae: 0.3870\n",
      "Epoch 321/2000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1950 - mae: 0.2794 - val_loss: 0.4056 - val_mae: 0.3872\n",
      "Epoch 322/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2121 - mae: 0.2881 - val_loss: 0.4183 - val_mae: 0.4009\n",
      "Epoch 323/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1985 - mae: 0.2826 - val_loss: 0.4326 - val_mae: 0.4065\n",
      "Epoch 324/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2016 - mae: 0.2816 - val_loss: 0.4260 - val_mae: 0.3922\n",
      "Epoch 325/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2058 - mae: 0.2894 - val_loss: 0.4122 - val_mae: 0.3807\n",
      "Epoch 326/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1876 - mae: 0.2695 - val_loss: 0.4141 - val_mae: 0.3905\n",
      "Epoch 327/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2029 - mae: 0.2827 - val_loss: 0.4201 - val_mae: 0.3932\n",
      "Epoch 328/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2032 - mae: 0.2811 - val_loss: 0.4333 - val_mae: 0.3977\n",
      "Epoch 329/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2003 - mae: 0.2803 - val_loss: 0.4228 - val_mae: 0.3912\n",
      "Epoch 330/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1982 - mae: 0.2879 - val_loss: 0.4201 - val_mae: 0.3958\n",
      "Epoch 331/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2021 - mae: 0.2841 - val_loss: 0.4324 - val_mae: 0.3964\n",
      "Epoch 332/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1994 - mae: 0.2777 - val_loss: 0.4556 - val_mae: 0.4101\n",
      "Epoch 333/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2115 - mae: 0.2877 - val_loss: 0.4291 - val_mae: 0.3978\n",
      "Epoch 334/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1927 - mae: 0.2829 - val_loss: 0.4051 - val_mae: 0.3799\n",
      "Epoch 335/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1932 - mae: 0.2788 - val_loss: 0.4067 - val_mae: 0.3816\n",
      "Epoch 336/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2026 - mae: 0.2881 - val_loss: 0.4294 - val_mae: 0.3967\n",
      "Epoch 337/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1931 - mae: 0.2772 - val_loss: 0.4496 - val_mae: 0.4041\n",
      "Epoch 338/2000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1973 - mae: 0.2822 - val_loss: 0.4460 - val_mae: 0.4029\n",
      "Epoch 339/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1928 - mae: 0.2722 - val_loss: 0.4331 - val_mae: 0.3913\n",
      "Epoch 340/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1803 - mae: 0.2663 - val_loss: 0.4278 - val_mae: 0.3879\n",
      "Epoch 341/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1882 - mae: 0.2747 - val_loss: 0.4332 - val_mae: 0.3940\n",
      "Epoch 342/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1854 - mae: 0.2680 - val_loss: 0.4316 - val_mae: 0.3946\n",
      "Epoch 343/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1851 - mae: 0.2685 - val_loss: 0.4277 - val_mae: 0.3967\n",
      "Epoch 344/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1878 - mae: 0.2632 - val_loss: 0.4214 - val_mae: 0.3938\n",
      "Epoch 345/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1861 - mae: 0.2726 - val_loss: 0.4170 - val_mae: 0.3868\n",
      "Epoch 346/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1928 - mae: 0.2750 - val_loss: 0.4158 - val_mae: 0.3839\n",
      "Epoch 347/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1991 - mae: 0.2789 - val_loss: 0.4291 - val_mae: 0.3929\n",
      "Epoch 348/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1779 - mae: 0.2626 - val_loss: 0.4513 - val_mae: 0.4123\n",
      "Epoch 349/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1800 - mae: 0.2622 - val_loss: 0.4503 - val_mae: 0.4053\n",
      "Epoch 350/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1992 - mae: 0.2804 - val_loss: 0.4275 - val_mae: 0.3899\n",
      "Epoch 351/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1903 - mae: 0.2715 - val_loss: 0.4208 - val_mae: 0.3865\n",
      "Epoch 352/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1893 - mae: 0.2697 - val_loss: 0.4338 - val_mae: 0.3952\n",
      "Epoch 353/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1925 - mae: 0.2778 - val_loss: 0.4509 - val_mae: 0.4049\n",
      "Epoch 354/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1825 - mae: 0.2679 - val_loss: 0.4557 - val_mae: 0.4049\n",
      "Epoch 355/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2099 - mae: 0.2935 - val_loss: 0.4417 - val_mae: 0.3992\n",
      "Epoch 356/2000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1885 - mae: 0.2750 - val_loss: 0.4220 - val_mae: 0.3907\n",
      "Epoch 357/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1825 - mae: 0.2683 - val_loss: 0.4128 - val_mae: 0.3885\n",
      "Epoch 358/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1825 - mae: 0.2652 - val_loss: 0.4259 - val_mae: 0.3957\n",
      "Epoch 359/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2045 - mae: 0.2838 - val_loss: 0.4391 - val_mae: 0.4027\n",
      "Epoch 360/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1813 - mae: 0.2675 - val_loss: 0.4341 - val_mae: 0.3955\n",
      "Epoch 361/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1928 - mae: 0.2731 - val_loss: 0.4395 - val_mae: 0.3912\n",
      "Epoch 362/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1803 - mae: 0.2637 - val_loss: 0.4481 - val_mae: 0.3930\n",
      "Epoch 363/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1925 - mae: 0.2746 - val_loss: 0.4518 - val_mae: 0.3960\n",
      "Epoch 364/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1930 - mae: 0.2748 - val_loss: 0.4474 - val_mae: 0.3994\n",
      "Epoch 365/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1822 - mae: 0.2658 - val_loss: 0.4502 - val_mae: 0.3987\n",
      "Epoch 366/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1839 - mae: 0.2720 - val_loss: 0.4444 - val_mae: 0.3911\n",
      "Epoch 367/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1799 - mae: 0.2630 - val_loss: 0.4291 - val_mae: 0.3827\n",
      "Epoch 368/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1767 - mae: 0.2671 - val_loss: 0.4289 - val_mae: 0.3878\n",
      "Epoch 369/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1809 - mae: 0.2677 - val_loss: 0.4364 - val_mae: 0.3943\n",
      "Epoch 370/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1769 - mae: 0.2594 - val_loss: 0.4521 - val_mae: 0.4033\n",
      "Epoch 371/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1890 - mae: 0.2777 - val_loss: 0.4419 - val_mae: 0.3966\n",
      "Epoch 372/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1929 - mae: 0.2682 - val_loss: 0.4409 - val_mae: 0.3973\n",
      "Epoch 373/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1861 - mae: 0.2669 - val_loss: 0.4346 - val_mae: 0.3930\n",
      "Epoch 374/2000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1803 - mae: 0.2696 - val_loss: 0.4255 - val_mae: 0.3917\n",
      "Epoch 375/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1805 - mae: 0.2697 - val_loss: 0.4354 - val_mae: 0.3947\n",
      "Epoch 376/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1852 - mae: 0.2699 - val_loss: 0.4499 - val_mae: 0.4052\n",
      "Epoch 377/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1781 - mae: 0.2654 - val_loss: 0.4475 - val_mae: 0.4002\n",
      "Epoch 378/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1780 - mae: 0.2615 - val_loss: 0.4433 - val_mae: 0.3909\n",
      "Epoch 379/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1713 - mae: 0.2583 - val_loss: 0.4481 - val_mae: 0.3866\n",
      "Epoch 380/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1820 - mae: 0.2694 - val_loss: 0.4476 - val_mae: 0.3870\n",
      "Epoch 381/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1812 - mae: 0.2683 - val_loss: 0.4310 - val_mae: 0.3900\n",
      "Epoch 382/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1797 - mae: 0.2670 - val_loss: 0.4233 - val_mae: 0.3920\n",
      "Epoch 383/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1749 - mae: 0.2609 - val_loss: 0.4361 - val_mae: 0.3991\n",
      "Epoch 384/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1804 - mae: 0.2658 - val_loss: 0.4448 - val_mae: 0.3972\n",
      "Epoch 385/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1868 - mae: 0.2713 - val_loss: 0.4409 - val_mae: 0.3945\n",
      "Epoch 386/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1717 - mae: 0.2588 - val_loss: 0.4325 - val_mae: 0.3919\n",
      "Epoch 387/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1783 - mae: 0.2643 - val_loss: 0.4423 - val_mae: 0.3998\n",
      "Epoch 388/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1806 - mae: 0.2690 - val_loss: 0.4534 - val_mae: 0.4012\n",
      "Epoch 389/2000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1795 - mae: 0.2665 - val_loss: 0.4510 - val_mae: 0.3907\n",
      "Epoch 390/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1783 - mae: 0.2729 - val_loss: 0.4354 - val_mae: 0.3864\n",
      "Epoch 391/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1792 - mae: 0.2684 - val_loss: 0.4347 - val_mae: 0.3931\n",
      "Epoch 392/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1783 - mae: 0.2672 - val_loss: 0.4452 - val_mae: 0.3947\n",
      "Epoch 393/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1751 - mae: 0.2641 - val_loss: 0.4604 - val_mae: 0.3995\n",
      "Epoch 394/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1728 - mae: 0.2580 - val_loss: 0.4521 - val_mae: 0.3924\n",
      "Epoch 395/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1766 - mae: 0.2636 - val_loss: 0.4389 - val_mae: 0.3915\n",
      "Epoch 396/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1718 - mae: 0.2620 - val_loss: 0.4328 - val_mae: 0.3895\n",
      "Epoch 397/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1856 - mae: 0.2730 - val_loss: 0.4420 - val_mae: 0.3919\n",
      "Epoch 398/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1749 - mae: 0.2633 - val_loss: 0.4563 - val_mae: 0.3938\n",
      "Epoch 399/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1738 - mae: 0.2616 - val_loss: 0.4535 - val_mae: 0.3909\n",
      "Epoch 400/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1800 - mae: 0.2697 - val_loss: 0.4390 - val_mae: 0.3946\n",
      "Epoch 401/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1763 - mae: 0.2613 - val_loss: 0.4380 - val_mae: 0.3982\n",
      "Epoch 402/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1780 - mae: 0.2559 - val_loss: 0.4448 - val_mae: 0.3947\n",
      "Epoch 403/2000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1750 - mae: 0.2544 - val_loss: 0.4504 - val_mae: 0.3957\n",
      "Epoch 404/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1830 - mae: 0.2627 - val_loss: 0.4342 - val_mae: 0.3869\n",
      "Epoch 405/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1695 - mae: 0.2543 - val_loss: 0.4440 - val_mae: 0.3926\n",
      "Epoch 406/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1672 - mae: 0.2508 - val_loss: 0.4509 - val_mae: 0.3962\n",
      "Epoch 407/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1663 - mae: 0.2537 - val_loss: 0.4500 - val_mae: 0.3982\n",
      "Epoch 408/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1698 - mae: 0.2592 - val_loss: 0.4410 - val_mae: 0.3923\n",
      "Epoch 409/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1632 - mae: 0.2581 - val_loss: 0.4328 - val_mae: 0.3849\n",
      "Epoch 410/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1690 - mae: 0.2595 - val_loss: 0.4399 - val_mae: 0.3887\n",
      "Epoch 411/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1740 - mae: 0.2639 - val_loss: 0.4646 - val_mae: 0.4005\n",
      "Epoch 412/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1670 - mae: 0.2548 - val_loss: 0.4733 - val_mae: 0.4047\n",
      "Epoch 413/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1698 - mae: 0.2581 - val_loss: 0.4458 - val_mae: 0.3944\n",
      "Epoch 414/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1683 - mae: 0.2567 - val_loss: 0.4289 - val_mae: 0.3837\n",
      "Epoch 415/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1739 - mae: 0.2653 - val_loss: 0.4621 - val_mae: 0.3965\n",
      "Epoch 416/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1804 - mae: 0.2622 - val_loss: 0.4683 - val_mae: 0.4026\n",
      "Epoch 417/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1910 - mae: 0.2637 - val_loss: 0.4483 - val_mae: 0.3989\n",
      "Epoch 418/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1685 - mae: 0.2633 - val_loss: 0.4363 - val_mae: 0.3912\n",
      "Epoch 419/2000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1624 - mae: 0.2503 - val_loss: 0.4499 - val_mae: 0.3882\n",
      "Epoch 420/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1851 - mae: 0.2679 - val_loss: 0.4538 - val_mae: 0.3940\n",
      "Epoch 421/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1844 - mae: 0.2660 - val_loss: 0.4487 - val_mae: 0.4006\n",
      "Epoch 422/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1736 - mae: 0.2635 - val_loss: 0.4493 - val_mae: 0.3986\n",
      "Epoch 423/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1709 - mae: 0.2576 - val_loss: 0.4790 - val_mae: 0.4111\n",
      "Epoch 424/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1697 - mae: 0.2587 - val_loss: 0.4832 - val_mae: 0.4077\n",
      "Epoch 425/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1651 - mae: 0.2554 - val_loss: 0.4689 - val_mae: 0.3955\n",
      "Epoch 426/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1805 - mae: 0.2644 - val_loss: 0.4639 - val_mae: 0.3924\n",
      "Epoch 427/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1778 - mae: 0.2603 - val_loss: 0.4700 - val_mae: 0.3930\n",
      "Epoch 428/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1790 - mae: 0.2663 - val_loss: 0.4600 - val_mae: 0.3924\n",
      "Epoch 429/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1770 - mae: 0.2637 - val_loss: 0.4480 - val_mae: 0.3915\n",
      "Epoch 430/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1751 - mae: 0.2585 - val_loss: 0.4521 - val_mae: 0.3958\n",
      "Epoch 431/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1674 - mae: 0.2550 - val_loss: 0.4662 - val_mae: 0.4017\n",
      "Epoch 432/2000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1661 - mae: 0.2566 - val_loss: 0.4653 - val_mae: 0.4032\n",
      "Epoch 433/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1687 - mae: 0.2574 - val_loss: 0.4543 - val_mae: 0.4041\n",
      "Epoch 434/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1738 - mae: 0.2644 - val_loss: 0.4541 - val_mae: 0.4066\n",
      "Epoch 435/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1721 - mae: 0.2656 - val_loss: 0.4606 - val_mae: 0.4035\n",
      "Epoch 436/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1715 - mae: 0.2597 - val_loss: 0.4787 - val_mae: 0.4106\n",
      "Epoch 437/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1688 - mae: 0.2542 - val_loss: 0.4541 - val_mae: 0.3966\n",
      "Epoch 438/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1745 - mae: 0.2627 - val_loss: 0.4312 - val_mae: 0.3848\n",
      "Epoch 439/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1695 - mae: 0.2593 - val_loss: 0.4460 - val_mae: 0.3895\n",
      "Epoch 440/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1762 - mae: 0.2606 - val_loss: 0.4574 - val_mae: 0.3995\n",
      "Epoch 441/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1686 - mae: 0.2512 - val_loss: 0.4573 - val_mae: 0.3992\n",
      "Epoch 442/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1646 - mae: 0.2496 - val_loss: 0.4513 - val_mae: 0.3946\n",
      "Epoch 443/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1665 - mae: 0.2589 - val_loss: 0.4464 - val_mae: 0.3913\n",
      "Epoch 444/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1717 - mae: 0.2599 - val_loss: 0.4416 - val_mae: 0.3888\n",
      "Epoch 445/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1646 - mae: 0.2542 - val_loss: 0.4397 - val_mae: 0.3931\n",
      "Epoch 446/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1770 - mae: 0.2644 - val_loss: 0.4503 - val_mae: 0.3976\n",
      "Epoch 447/2000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1561 - mae: 0.2484 - val_loss: 0.4328 - val_mae: 0.3889\n",
      "Epoch 448/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1624 - mae: 0.2550 - val_loss: 0.4314 - val_mae: 0.3842\n",
      "Epoch 449/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1633 - mae: 0.2478 - val_loss: 0.4456 - val_mae: 0.3924\n",
      "Epoch 450/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1707 - mae: 0.2607 - val_loss: 0.4641 - val_mae: 0.4032\n",
      "Epoch 451/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1653 - mae: 0.2518 - val_loss: 0.4670 - val_mae: 0.3970\n",
      "Epoch 452/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1605 - mae: 0.2441 - val_loss: 0.4649 - val_mae: 0.3899\n",
      "Epoch 453/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1589 - mae: 0.2493 - val_loss: 0.4704 - val_mae: 0.3916\n",
      "Epoch 454/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1614 - mae: 0.2488 - val_loss: 0.4911 - val_mae: 0.3995\n",
      "Epoch 455/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1616 - mae: 0.2518 - val_loss: 0.4832 - val_mae: 0.3969\n",
      "Epoch 456/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1584 - mae: 0.2460 - val_loss: 0.4558 - val_mae: 0.3881\n",
      "Epoch 457/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1678 - mae: 0.2552 - val_loss: 0.4474 - val_mae: 0.3831\n",
      "Epoch 458/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1625 - mae: 0.2485 - val_loss: 0.4545 - val_mae: 0.3829\n",
      "Epoch 459/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1576 - mae: 0.2406 - val_loss: 0.4605 - val_mae: 0.3917\n",
      "Epoch 460/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1660 - mae: 0.2488 - val_loss: 0.4544 - val_mae: 0.3953\n",
      "Epoch 461/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1583 - mae: 0.2484 - val_loss: 0.4366 - val_mae: 0.3818\n",
      "Epoch 462/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1626 - mae: 0.2568 - val_loss: 0.4316 - val_mae: 0.3750\n",
      "Epoch 463/2000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1588 - mae: 0.2500 - val_loss: 0.4266 - val_mae: 0.3755\n",
      "Epoch 464/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1611 - mae: 0.2486 - val_loss: 0.4248 - val_mae: 0.3789\n",
      "Epoch 465/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1581 - mae: 0.2462 - val_loss: 0.4280 - val_mae: 0.3837\n",
      "Epoch 466/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1603 - mae: 0.2540 - val_loss: 0.4413 - val_mae: 0.3772\n",
      "Epoch 467/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1540 - mae: 0.2456 - val_loss: 0.4478 - val_mae: 0.3735\n",
      "Epoch 468/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1576 - mae: 0.2493 - val_loss: 0.4435 - val_mae: 0.3787\n",
      "Epoch 469/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1705 - mae: 0.2624 - val_loss: 0.4504 - val_mae: 0.3924\n",
      "Epoch 470/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1584 - mae: 0.2480 - val_loss: 0.4422 - val_mae: 0.3880\n",
      "Epoch 471/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1650 - mae: 0.2597 - val_loss: 0.4462 - val_mae: 0.3836\n",
      "Epoch 472/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1686 - mae: 0.2542 - val_loss: 0.4669 - val_mae: 0.3915\n",
      "Epoch 473/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1545 - mae: 0.2462 - val_loss: 0.4698 - val_mae: 0.3953\n",
      "Epoch 474/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1615 - mae: 0.2551 - val_loss: 0.4585 - val_mae: 0.3895\n",
      "Epoch 475/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1702 - mae: 0.2551 - val_loss: 0.4622 - val_mae: 0.3912\n",
      "Epoch 476/2000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1571 - mae: 0.2486 - val_loss: 0.4464 - val_mae: 0.3827\n",
      "Epoch 477/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1652 - mae: 0.2478 - val_loss: 0.4532 - val_mae: 0.3930\n",
      "Epoch 478/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1568 - mae: 0.2522 - val_loss: 0.4657 - val_mae: 0.4088\n",
      "Epoch 479/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1603 - mae: 0.2486 - val_loss: 0.4825 - val_mae: 0.4232\n",
      "Epoch 480/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1573 - mae: 0.2428 - val_loss: 0.4824 - val_mae: 0.4164\n",
      "Epoch 481/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1602 - mae: 0.2541 - val_loss: 0.4665 - val_mae: 0.4006\n",
      "Epoch 482/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1598 - mae: 0.2538 - val_loss: 0.4468 - val_mae: 0.3960\n",
      "Epoch 483/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1551 - mae: 0.2534 - val_loss: 0.4452 - val_mae: 0.3961\n",
      "Epoch 484/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1539 - mae: 0.2471 - val_loss: 0.4518 - val_mae: 0.4026\n",
      "Epoch 485/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1622 - mae: 0.2560 - val_loss: 0.4431 - val_mae: 0.3895\n",
      "Epoch 486/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1563 - mae: 0.2420 - val_loss: 0.4333 - val_mae: 0.3854\n",
      "Epoch 487/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1596 - mae: 0.2447 - val_loss: 0.4524 - val_mae: 0.3997\n",
      "Epoch 488/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1644 - mae: 0.2509 - val_loss: 0.4647 - val_mae: 0.4004\n",
      "Epoch 489/2000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1645 - mae: 0.2594 - val_loss: 0.4411 - val_mae: 0.3888\n",
      "Epoch 490/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1605 - mae: 0.2509 - val_loss: 0.4335 - val_mae: 0.3905\n",
      "Epoch 491/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1636 - mae: 0.2555 - val_loss: 0.4433 - val_mae: 0.3891\n",
      "Epoch 492/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1580 - mae: 0.2472 - val_loss: 0.4512 - val_mae: 0.3861\n",
      "Epoch 493/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1564 - mae: 0.2484 - val_loss: 0.4465 - val_mae: 0.3821\n",
      "Epoch 494/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1618 - mae: 0.2527 - val_loss: 0.4582 - val_mae: 0.3861\n",
      "Epoch 495/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1619 - mae: 0.2571 - val_loss: 0.4719 - val_mae: 0.3940\n",
      "Epoch 496/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1594 - mae: 0.2533 - val_loss: 0.4715 - val_mae: 0.4012\n",
      "Epoch 497/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1624 - mae: 0.2526 - val_loss: 0.4481 - val_mae: 0.3953\n",
      "Epoch 498/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1520 - mae: 0.2446 - val_loss: 0.4415 - val_mae: 0.3898\n",
      "Epoch 499/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1577 - mae: 0.2551 - val_loss: 0.4510 - val_mae: 0.4008\n",
      "Epoch 500/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1610 - mae: 0.2472 - val_loss: 0.4559 - val_mae: 0.4021\n",
      "Epoch 501/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1458 - mae: 0.2400 - val_loss: 0.4659 - val_mae: 0.4012\n",
      "Epoch 502/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1481 - mae: 0.2425 - val_loss: 0.4672 - val_mae: 0.3935\n",
      "Epoch 503/2000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1487 - mae: 0.2458 - val_loss: 0.4560 - val_mae: 0.3843\n",
      "Epoch 504/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1580 - mae: 0.2482 - val_loss: 0.4444 - val_mae: 0.3827\n",
      "Epoch 505/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1578 - mae: 0.2466 - val_loss: 0.4462 - val_mae: 0.3922\n",
      "Epoch 506/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1564 - mae: 0.2464 - val_loss: 0.4582 - val_mae: 0.4056\n",
      "Epoch 507/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1479 - mae: 0.2364 - val_loss: 0.4548 - val_mae: 0.4006\n",
      "Epoch 508/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1612 - mae: 0.2484 - val_loss: 0.4400 - val_mae: 0.3837\n",
      "Epoch 509/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1493 - mae: 0.2390 - val_loss: 0.4280 - val_mae: 0.3742\n",
      "Epoch 510/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1493 - mae: 0.2397 - val_loss: 0.4243 - val_mae: 0.3772\n",
      "Epoch 511/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1535 - mae: 0.2436 - val_loss: 0.4287 - val_mae: 0.3850\n",
      "Epoch 512/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1477 - mae: 0.2395 - val_loss: 0.4497 - val_mae: 0.3951\n",
      "Epoch 513/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1523 - mae: 0.2394 - val_loss: 0.4460 - val_mae: 0.3878\n",
      "Epoch 514/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1553 - mae: 0.2428 - val_loss: 0.4442 - val_mae: 0.3887\n",
      "Epoch 515/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1478 - mae: 0.2402 - val_loss: 0.4635 - val_mae: 0.4036\n",
      "Epoch 516/2000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1572 - mae: 0.2512 - val_loss: 0.4817 - val_mae: 0.4063\n",
      "Epoch 517/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1508 - mae: 0.2427 - val_loss: 0.4684 - val_mae: 0.3999\n",
      "Epoch 518/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1551 - mae: 0.2489 - val_loss: 0.4523 - val_mae: 0.3943\n",
      "Epoch 519/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1518 - mae: 0.2432 - val_loss: 0.4491 - val_mae: 0.3952\n",
      "Epoch 520/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1541 - mae: 0.2452 - val_loss: 0.4566 - val_mae: 0.3936\n",
      "Epoch 521/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1588 - mae: 0.2525 - val_loss: 0.4647 - val_mae: 0.3863\n",
      "Epoch 522/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1499 - mae: 0.2424 - val_loss: 0.4730 - val_mae: 0.3876\n",
      "Epoch 523/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1488 - mae: 0.2388 - val_loss: 0.4633 - val_mae: 0.3847\n",
      "Epoch 524/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1562 - mae: 0.2484 - val_loss: 0.4599 - val_mae: 0.3876\n",
      "Epoch 525/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1531 - mae: 0.2472 - val_loss: 0.4588 - val_mae: 0.3898\n",
      "Epoch 526/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1510 - mae: 0.2388 - val_loss: 0.4650 - val_mae: 0.3903\n",
      "Epoch 527/2000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1446 - mae: 0.2324 - val_loss: 0.4516 - val_mae: 0.3836\n",
      "Epoch 528/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1514 - mae: 0.2421 - val_loss: 0.4436 - val_mae: 0.3797\n",
      "Epoch 529/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1477 - mae: 0.2422 - val_loss: 0.4530 - val_mae: 0.3845\n",
      "Epoch 530/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1495 - mae: 0.2441 - val_loss: 0.4505 - val_mae: 0.3828\n",
      "Epoch 531/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1532 - mae: 0.2445 - val_loss: 0.4428 - val_mae: 0.3791\n",
      "Epoch 532/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1547 - mae: 0.2458 - val_loss: 0.4282 - val_mae: 0.3777\n",
      "Epoch 533/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1581 - mae: 0.2430 - val_loss: 0.4272 - val_mae: 0.3864\n",
      "Epoch 534/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1478 - mae: 0.2423 - val_loss: 0.4251 - val_mae: 0.3833\n",
      "Epoch 535/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1554 - mae: 0.2508 - val_loss: 0.4189 - val_mae: 0.3727\n",
      "Epoch 536/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1522 - mae: 0.2417 - val_loss: 0.4080 - val_mae: 0.3719\n",
      "Epoch 537/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1444 - mae: 0.2384 - val_loss: 0.4222 - val_mae: 0.3850\n",
      "Epoch 538/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1514 - mae: 0.2424 - val_loss: 0.4347 - val_mae: 0.3886\n",
      "Epoch 539/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1442 - mae: 0.2397 - val_loss: 0.4401 - val_mae: 0.3861\n",
      "Epoch 540/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1457 - mae: 0.2357 - val_loss: 0.4315 - val_mae: 0.3808\n",
      "Epoch 541/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1444 - mae: 0.2398 - val_loss: 0.4427 - val_mae: 0.3873\n",
      "Epoch 542/2000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1521 - mae: 0.2441 - val_loss: 0.4524 - val_mae: 0.3921\n",
      "Epoch 543/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1470 - mae: 0.2345 - val_loss: 0.4549 - val_mae: 0.3890\n",
      "Epoch 544/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1522 - mae: 0.2446 - val_loss: 0.4577 - val_mae: 0.3854\n",
      "Epoch 545/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1540 - mae: 0.2438 - val_loss: 0.4500 - val_mae: 0.3797\n",
      "Epoch 546/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1503 - mae: 0.2477 - val_loss: 0.4419 - val_mae: 0.3779\n",
      "Epoch 547/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1488 - mae: 0.2364 - val_loss: 0.4681 - val_mae: 0.3934\n",
      "Epoch 548/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1545 - mae: 0.2420 - val_loss: 0.4760 - val_mae: 0.3987\n",
      "Epoch 549/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1453 - mae: 0.2388 - val_loss: 0.4728 - val_mae: 0.4048\n",
      "Epoch 550/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1542 - mae: 0.2467 - val_loss: 0.4656 - val_mae: 0.4077\n",
      "Epoch 551/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1424 - mae: 0.2295 - val_loss: 0.4754 - val_mae: 0.4017\n",
      "Epoch 552/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1452 - mae: 0.2403 - val_loss: 0.4713 - val_mae: 0.3917\n",
      "Epoch 553/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1501 - mae: 0.2419 - val_loss: 0.4569 - val_mae: 0.3862\n",
      "Epoch 554/2000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1410 - mae: 0.2356 - val_loss: 0.4405 - val_mae: 0.3828\n",
      "Epoch 555/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1486 - mae: 0.2418 - val_loss: 0.4372 - val_mae: 0.3828\n",
      "Epoch 556/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1389 - mae: 0.2325 - val_loss: 0.4456 - val_mae: 0.3870\n",
      "Epoch 557/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1449 - mae: 0.2414 - val_loss: 0.4429 - val_mae: 0.3869\n",
      "Epoch 558/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1412 - mae: 0.2341 - val_loss: 0.4340 - val_mae: 0.3833\n",
      "Epoch 559/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1514 - mae: 0.2459 - val_loss: 0.4397 - val_mae: 0.3866\n",
      "Epoch 560/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1521 - mae: 0.2443 - val_loss: 0.4469 - val_mae: 0.3865\n",
      "Epoch 561/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1523 - mae: 0.2487 - val_loss: 0.4548 - val_mae: 0.3937\n",
      "Epoch 562/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1505 - mae: 0.2431 - val_loss: 0.4604 - val_mae: 0.3960\n",
      "Epoch 563/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1394 - mae: 0.2324 - val_loss: 0.4419 - val_mae: 0.3873\n",
      "Epoch 564/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1399 - mae: 0.2382 - val_loss: 0.4484 - val_mae: 0.3881\n",
      "Epoch 565/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1391 - mae: 0.2350 - val_loss: 0.4587 - val_mae: 0.3961\n",
      "Epoch 566/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1497 - mae: 0.2391 - val_loss: 0.4888 - val_mae: 0.4105\n",
      "Epoch 567/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1439 - mae: 0.2421 - val_loss: 0.4808 - val_mae: 0.4043\n",
      "Epoch 568/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1410 - mae: 0.2392 - val_loss: 0.4540 - val_mae: 0.3914\n",
      "Epoch 569/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1433 - mae: 0.2449 - val_loss: 0.4509 - val_mae: 0.3893\n",
      "Epoch 570/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1473 - mae: 0.2386 - val_loss: 0.4580 - val_mae: 0.3874\n",
      "Epoch 571/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1460 - mae: 0.2304 - val_loss: 0.4806 - val_mae: 0.3994\n",
      "Epoch 572/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1437 - mae: 0.2374 - val_loss: 0.4874 - val_mae: 0.3976\n",
      "Epoch 573/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1475 - mae: 0.2412 - val_loss: 0.4679 - val_mae: 0.3831\n",
      "Epoch 574/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1430 - mae: 0.2386 - val_loss: 0.4441 - val_mae: 0.3823\n",
      "Epoch 575/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1492 - mae: 0.2455 - val_loss: 0.4322 - val_mae: 0.3891\n",
      "Epoch 576/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1581 - mae: 0.2534 - val_loss: 0.4669 - val_mae: 0.3990\n",
      "Epoch 577/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1487 - mae: 0.2469 - val_loss: 0.4972 - val_mae: 0.4039\n",
      "Epoch 578/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1447 - mae: 0.2360 - val_loss: 0.4581 - val_mae: 0.3854\n",
      "Epoch 579/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1415 - mae: 0.2387 - val_loss: 0.4228 - val_mae: 0.3749\n",
      "Epoch 580/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1483 - mae: 0.2457 - val_loss: 0.4353 - val_mae: 0.3870\n",
      "Epoch 581/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1469 - mae: 0.2430 - val_loss: 0.4842 - val_mae: 0.4008\n",
      "Epoch 582/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1514 - mae: 0.2433 - val_loss: 0.5089 - val_mae: 0.4094\n",
      "Epoch 583/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1476 - mae: 0.2426 - val_loss: 0.4654 - val_mae: 0.3912\n",
      "Epoch 584/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1546 - mae: 0.2490 - val_loss: 0.4438 - val_mae: 0.3834\n",
      "Epoch 585/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1412 - mae: 0.2354 - val_loss: 0.4798 - val_mae: 0.3962\n",
      "Epoch 586/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1531 - mae: 0.2505 - val_loss: 0.4779 - val_mae: 0.4011\n",
      "Epoch 587/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1465 - mae: 0.2371 - val_loss: 0.4605 - val_mae: 0.4011\n",
      "Epoch 588/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1434 - mae: 0.2392 - val_loss: 0.4661 - val_mae: 0.4046\n",
      "Epoch 589/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1501 - mae: 0.2417 - val_loss: 0.4850 - val_mae: 0.4028\n",
      "Epoch 590/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1499 - mae: 0.2436 - val_loss: 0.4724 - val_mae: 0.3936\n",
      "Epoch 591/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1512 - mae: 0.2461 - val_loss: 0.4545 - val_mae: 0.3896\n",
      "Epoch 592/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1412 - mae: 0.2373 - val_loss: 0.4658 - val_mae: 0.3948\n",
      "Epoch 593/2000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1522 - mae: 0.2464 - val_loss: 0.4668 - val_mae: 0.3890\n",
      "Epoch 594/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1465 - mae: 0.2467 - val_loss: 0.4527 - val_mae: 0.3852\n",
      "Epoch 595/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1409 - mae: 0.2323 - val_loss: 0.4421 - val_mae: 0.3865\n",
      "Epoch 596/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1416 - mae: 0.2316 - val_loss: 0.4607 - val_mae: 0.4014\n",
      "Epoch 597/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1460 - mae: 0.2448 - val_loss: 0.4683 - val_mae: 0.4030\n",
      "Epoch 598/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1418 - mae: 0.2369 - val_loss: 0.4561 - val_mae: 0.3948\n",
      "Epoch 599/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1455 - mae: 0.2369 - val_loss: 0.4600 - val_mae: 0.3882\n",
      "Epoch 600/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1321 - mae: 0.2234 - val_loss: 0.4661 - val_mae: 0.3901\n",
      "Epoch 601/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1485 - mae: 0.2389 - val_loss: 0.4451 - val_mae: 0.3831\n",
      "Epoch 602/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1408 - mae: 0.2387 - val_loss: 0.4337 - val_mae: 0.3806\n",
      "Epoch 603/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1505 - mae: 0.2339 - val_loss: 0.4535 - val_mae: 0.3807\n",
      "Epoch 604/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1401 - mae: 0.2306 - val_loss: 0.4697 - val_mae: 0.3823\n",
      "Epoch 605/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1513 - mae: 0.2468 - val_loss: 0.4487 - val_mae: 0.3773\n",
      "Epoch 606/2000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1305 - mae: 0.2271 - val_loss: 0.4245 - val_mae: 0.3789\n",
      "Epoch 607/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1441 - mae: 0.2354 - val_loss: 0.4497 - val_mae: 0.3915\n",
      "Epoch 608/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1410 - mae: 0.2253 - val_loss: 0.4727 - val_mae: 0.3996\n",
      "Epoch 609/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1497 - mae: 0.2459 - val_loss: 0.4565 - val_mae: 0.3871\n",
      "Epoch 610/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1428 - mae: 0.2392 - val_loss: 0.4362 - val_mae: 0.3816\n",
      "Epoch 611/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1388 - mae: 0.2399 - val_loss: 0.4355 - val_mae: 0.3839\n",
      "Epoch 612/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1418 - mae: 0.2340 - val_loss: 0.4457 - val_mae: 0.3922\n",
      "Epoch 613/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1562 - mae: 0.2488 - val_loss: 0.4381 - val_mae: 0.3844\n",
      "Epoch 614/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1304 - mae: 0.2234 - val_loss: 0.4414 - val_mae: 0.3889\n",
      "Epoch 615/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1424 - mae: 0.2355 - val_loss: 0.4447 - val_mae: 0.3935\n",
      "Epoch 616/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1484 - mae: 0.2404 - val_loss: 0.4523 - val_mae: 0.3976\n",
      "Epoch 617/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1433 - mae: 0.2457 - val_loss: 0.4570 - val_mae: 0.3934\n",
      "Epoch 618/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1501 - mae: 0.2515 - val_loss: 0.4503 - val_mae: 0.3896\n",
      "Epoch 619/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1370 - mae: 0.2344 - val_loss: 0.4367 - val_mae: 0.3874\n",
      "Epoch 620/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1397 - mae: 0.2300 - val_loss: 0.4485 - val_mae: 0.3938\n",
      "Epoch 621/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1563 - mae: 0.2407 - val_loss: 0.4436 - val_mae: 0.3879\n",
      "Epoch 622/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1383 - mae: 0.2276 - val_loss: 0.4376 - val_mae: 0.3795\n",
      "Epoch 623/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1324 - mae: 0.2312 - val_loss: 0.4394 - val_mae: 0.3787\n",
      "Epoch 624/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1388 - mae: 0.2306 - val_loss: 0.4593 - val_mae: 0.3932\n",
      "Epoch 625/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1404 - mae: 0.2326 - val_loss: 0.4735 - val_mae: 0.4037\n",
      "Epoch 626/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1400 - mae: 0.2312 - val_loss: 0.4319 - val_mae: 0.3840\n",
      "Epoch 627/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1400 - mae: 0.2343 - val_loss: 0.4167 - val_mae: 0.3764\n",
      "Epoch 628/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1458 - mae: 0.2335 - val_loss: 0.4392 - val_mae: 0.3832\n",
      "Epoch 629/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1323 - mae: 0.2287 - val_loss: 0.4822 - val_mae: 0.4035\n",
      "Epoch 630/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1415 - mae: 0.2394 - val_loss: 0.4819 - val_mae: 0.4016\n",
      "Epoch 631/2000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1389 - mae: 0.2389 - val_loss: 0.4390 - val_mae: 0.3850\n",
      "Epoch 632/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1365 - mae: 0.2326 - val_loss: 0.4163 - val_mae: 0.3695\n",
      "Epoch 633/2000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1543 - mae: 0.2439 - val_loss: 0.4403 - val_mae: 0.3824\n",
      "Epoch 634/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1359 - mae: 0.2315 - val_loss: 0.4439 - val_mae: 0.3879\n",
      "Epoch 635/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1435 - mae: 0.2408 - val_loss: 0.4348 - val_mae: 0.3857\n",
      "Epoch 636/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1457 - mae: 0.2367 - val_loss: 0.4483 - val_mae: 0.3937\n",
      "Epoch 637/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1620 - mae: 0.2448 - val_loss: 0.4522 - val_mae: 0.3919\n",
      "Epoch 638/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1400 - mae: 0.2352 - val_loss: 0.4673 - val_mae: 0.3939\n",
      "Epoch 639/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1375 - mae: 0.2310 - val_loss: 0.4809 - val_mae: 0.3992\n",
      "Epoch 640/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1478 - mae: 0.2353 - val_loss: 0.4949 - val_mae: 0.4088\n",
      "Epoch 641/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1421 - mae: 0.2331 - val_loss: 0.4488 - val_mae: 0.3859\n",
      "Epoch 642/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1433 - mae: 0.2403 - val_loss: 0.4347 - val_mae: 0.3810\n",
      "Epoch 643/2000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1329 - mae: 0.2319 - val_loss: 0.4471 - val_mae: 0.3854\n",
      "Epoch 644/2000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1444 - mae: 0.2385 - val_loss: 0.4634 - val_mae: 0.3929\n",
      "Epoch 645/2000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1368 - mae: 0.2375 - val_loss: 0.4542 - val_mae: 0.3875\n",
      "Epoch 646/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1436 - mae: 0.2373 - val_loss: 0.4598 - val_mae: 0.3939\n",
      "Epoch 647/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1441 - mae: 0.2424 - val_loss: 0.4661 - val_mae: 0.3935\n",
      "Epoch 648/2000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1396 - mae: 0.2405 - val_loss: 0.4591 - val_mae: 0.3876\n",
      "Epoch 649/2000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1333 - mae: 0.2327 - val_loss: 0.4508 - val_mae: 0.3849\n",
      "Epoch 650/2000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1328 - mae: 0.2273 - val_loss: 0.4513 - val_mae: 0.3880\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# # Define the model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.SimpleRNN(32, activation='relu', input_shape=(15, 7)),  # Input layer\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),  # Hidden layer\n",
    "#     tf.keras.layers.Dense(4 * 7, activation=None)  # Output layer to predict 16 timesteps, each with 20 features\n",
    "# ])\n",
    "# model.add(tf.keras.layers.Reshape((4, 7)))  # Reshape output to match (16, 20)\n",
    "\n",
    "# Define the LSTM model with dropout\n",
    "model = tf.keras.Sequential([\n",
    "    # Adding dropout and recurrent dropout to the LSTM layer\n",
    "    tf.keras.layers.LSTM(32, activation='relu', input_shape=(15, 7),\n",
    "                         dropout=0.2, recurrent_dropout=0.2),\n",
    "    # Adding L2 regularization to the Dense layer\n",
    "    tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    # Output layer to predict 8 timesteps, each with 20 features\n",
    "    tf.keras.layers.Dense(4 * 7, activation=None)\n",
    "])\n",
    "model.add(tf.keras.layers.Reshape((4, 7)))  # Reshape output to match (8, 20)\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='mae', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Define optimizer\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2000, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step\n",
      "Test MAE: 0.3901\n",
      "Test RMSE: 0.6735\n",
      "Test R-squared: 0.6465\n",
      "Test MAE for CO2: 0.5887\n",
      "Test RMSE for CO2: 0.9495\n",
      "Test R-squared for CO2: 0.5631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Flatten the predictions and actual values for metric calculations\n",
    "y_true_flat = y_test.reshape(-1)\n",
    "y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "# Calculate metrics\n",
    "test_mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
    "test_r2 = r2_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Test MAE: {test_mae:.4f}')\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "print(f'Test R-squared: {test_r2:.4f}')\n",
    "\n",
    "\n",
    "# Extracting predictions for CO2 (assuming it's the first column in the output)\n",
    "y_pred_co2 = y_pred[:, :, 0]  # Adjust the index if CO2 is not the first column\n",
    "y_true_co2 = y_test[:, :, 0]\n",
    "\n",
    "# Flatten the CO2 predictions and actual values\n",
    "y_true_co2_flat = y_true_co2.reshape(-1)\n",
    "y_pred_co2_flat = y_pred_co2.reshape(-1)\n",
    "\n",
    "# Calculate metrics for CO2\n",
    "test_mae_co2 = mean_absolute_error(y_true_co2_flat, y_pred_co2_flat)\n",
    "test_rmse_co2 = np.sqrt(mean_squared_error(y_true_co2_flat, y_pred_co2_flat))\n",
    "test_r2_co2 = r2_score(y_true_co2_flat, y_pred_co2_flat)\n",
    "\n",
    "# Print the metrics for CO2\n",
    "print(f'Test MAE for CO2: {test_mae_co2:.4f}')\n",
    "print(f'Test RMSE for CO2: {test_rmse_co2:.4f}')\n",
    "print(f'Test R-squared for CO2: {test_r2_co2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calculate_r2_per_feature(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the R-squared score for each feature across all timesteps.\n",
    "    Args:\n",
    "    y_true (numpy.ndarray): True values of the test set.\n",
    "    y_pred (numpy.ndarray): Predicted values from the model.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with feature indices as keys and R-squared scores as values.\n",
    "    \"\"\"\n",
    "    r2_scores = {}\n",
    "    for feature_index in range(y_true.shape[2]):  # Assuming the last dimension represents features\n",
    "        y_true_feature = y_true[:, :, feature_index].reshape(-1)\n",
    "        y_pred_feature = y_pred[:, :, feature_index].reshape(-1)\n",
    "        r2_scores[feature_index] = r2_score(y_true_feature, y_pred_feature)\n",
    "    return r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared scores for each feature: {0: 0.5631207410400711, 1: 0.49286709176845833, 2: 0.8821879560782109, 3: 0.8929307098455981, 4: 0.5245914859980021, 5: 0.9620197797356367, 6: 0.2504928371569689}\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test and y_pred are already defined and contain the test and predicted data respectively.\n",
    "r2_scores = calculate_r2_per_feature(y_test, y_pred)\n",
    "print(\"R-squared scores for each feature:\", r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract feature names if available or use generic names\n",
    "feature_names = ['Feature {}'.format(i) for i in range(y_test.shape[2])]  # Adjust or replace with actual names\n",
    "\n",
    "# Extract R2 values and sort by value\n",
    "r2_values = [r2_scores[i] for i in sorted(r2_scores)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, r2_values, color='blue')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('R-squared Score')\n",
    "plt.title('R-squared Score for Each Feature')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to make room for label rotation\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
